
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>5.1 Prompt Injection</title>
    <link rel="stylesheet" href="../../assets/css/main.css">
    <style>
        body {
            max-width: 900px;
            margin: 0 auto;
            padding: 2rem;
            background-color: #0f0f1a;
        }
        .reader-container {
            background: #1a1a2e;
            padding: 3rem;
            border-radius: 12px;
            box-shadow: 0 4px 20px rgba(0,0,0,0.3);
        }
        .meta-header {
            margin-bottom: 2rem;
            padding-bottom: 1rem;
            border-bottom: 1px solid #30363d;
        }
        
        /* Markdown Content Styles */
        h1, h2, h3 { color: #e0e0e0; margin-top: 1.5rem; }
        p { line-height: 1.6; color: #c9d1d9; margin-bottom: 1rem; }
        ul, ol { color: #c9d1d9; margin-bottom: 1rem; padding-left: 2rem; }
        li { margin-bottom: 0.5rem; }
        pre { background: #0d1117; padding: 1rem; border-radius: 6px; overflow-x: auto; margin: 1rem 0; }
        code { font-family: 'Fira Code', monospace; color: #e0e0e0; background: rgba(110, 118, 129, 0.4); padding: 0.2em 0.4em; border-radius: 6px; }
        pre code { background: transparent; padding: 0; }
        a { color: #58a6ff; text-decoration: none; }
        a:hover { text-decoration: underline; }
        blockquote { border-left: 4px solid #58a6ff; padding-left: 1rem; color: #8b949e; margin: 1rem 0; }
        table { border-collapse: collapse; width: 100%; margin: 1rem 0; }
        th, td { border: 1px solid #30363d; padding: 0.5rem; text-align: left; color: #c9d1d9; }
        th { background: #161b22; }
    </style>
</head>
<body>
    <div class="reader-container">
        <div class="meta-header">
            <h1>5.1 Prompt Injection</h1>
            <p>Type: topic</p>
        </div>
        <div class="content">
            <p><strong>What:</strong> Malicious text in documents can hijack LLM behavior.</p>
<p><strong>Resources:</strong></p>
<ol>
<li>
<p><strong>OWASP LLM Top 10</strong><br />
https://owasp.org/www-project-top-10-for-large-language-model-applications/</p>
</li>
<li>
<p><strong>Prompt Injection Explained</strong><br />
https://simonwillison.net/2022/Sep/12/prompt-injection/</p>
</li>
</ol>
<p><strong>Mitigations:</strong></p>
<ul>
<li>Treat retrieved chunks as untrusted data</li>
<li>Use structured outputs (harder to hijack)</li>
<li>Validate LLM output before returning</li>
</ul>
<hr />

        </div>
    </div>
</body>
</html>
