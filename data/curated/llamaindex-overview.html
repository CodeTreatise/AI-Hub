<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <link rel="icon" type="image/svg+xml" href="../../assets/favicon.svg">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LlamaIndex - RAG Framework Overview</title>
    <style>
        body { max-width: 900px; margin: 0 auto; padding: 2rem; background-color: #0f0f1a; font-family: 'Segoe UI', system-ui, sans-serif; }
        .reader-container { background: #1a1a2e; padding: 3rem; border-radius: 12px; box-shadow: 0 4px 20px rgba(0,0,0,0.3); }
        .meta-header { margin-bottom: 2rem; padding-bottom: 1rem; border-bottom: 1px solid #30363d; }
        .meta-header h1 { color: #e0e0e0; margin: 0 0 1rem 0; }
        .meta-header a { color: #58a6ff; }
        .content { color: #c9d1d9; line-height: 1.7; }
        .content h2 { color: #e0e0e0; margin-top: 2rem; border-bottom: 1px solid #30363d; padding-bottom: 0.5rem; }
        .content h3 { color: #e0e0e0; margin-top: 1.5rem; }
        .content ul { margin: 1rem 0; padding-left: 1.5rem; }
        .content li { margin: 0.5rem 0; }
        .content code { background: #0d1117; padding: 2px 6px; border-radius: 4px; font-family: 'Fira Code', monospace; }
        .content pre { background: #0d1117; padding: 1rem; border-radius: 6px; overflow-x: auto; }
        .content pre code { padding: 0; background: none; }
        .feature { background: #1a2a3a; padding: 1rem; border-radius: 8px; margin: 0.75rem 0; border-left: 4px solid #58a6ff; }
        .feature h4 { color: #58a6ff; margin: 0 0 0.5rem 0; }
        .tip { background: #1a3a2a; border-left: 4px solid #3fb950; padding: 1rem; border-radius: 4px; margin: 1rem 0; }
        .links { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 0.75rem; margin: 1rem 0; }
        .links a { background: #0d1117; padding: 0.75rem 1rem; border-radius: 6px; color: #58a6ff; text-decoration: none; display: block; }
        .links a:hover { background: #1a2a3a; }
    </style>
</head>
<body>
    <div class="reader-container">
        <div class="meta-header">
            <h1>ü¶ô LlamaIndex - RAG Framework Overview</h1>
            <p>Source: <a href="https://docs.llamaindex.ai/" target="_blank">docs.llamaindex.ai</a></p>
        </div>
        <div class="content">
            <h2>What is LlamaIndex?</h2>
            <p>LlamaIndex is the leading framework for building LLM-powered applications over your data. It provides tools for data ingestion, indexing, and querying‚Äîeverything you need for production RAG and AI agents.</p>
            
            <div class="tip">
                <strong>üéØ When to use LlamaIndex:</strong> When you need production-ready RAG with advanced features like agents, workflows, and multiple data sources. Great for complex apps, but consider building from scratch first to understand the fundamentals.
            </div>
            
            <h2>Core Components</h2>
            
            <div class="feature">
                <h4>üì• Data Connectors</h4>
                <p>Ingest data from APIs, PDFs, databases, web pages, Notion, Slack, Google Drive, and 100+ sources via <a href="https://llamahub.ai/" target="_blank">LlamaHub</a>.</p>
            </div>
            
            <div class="feature">
                <h4>üìä Data Indexes</h4>
                <p>Structure your data for efficient retrieval. Supports vector stores, keyword indexes, knowledge graphs, and hybrid approaches.</p>
            </div>
            
            <div class="feature">
                <h4>üîç Query Engines</h4>
                <p>Powerful interfaces for question-answering. Handles retrieval, reranking, and response synthesis.</p>
            </div>
            
            <div class="feature">
                <h4>üí¨ Chat Engines</h4>
                <p>Conversational interfaces with memory for multi-turn dialogue over your data.</p>
            </div>
            
            <div class="feature">
                <h4>ü§ñ Agents</h4>
                <p>LLM-powered workers that use tools (including RAG) to complete complex tasks autonomously.</p>
            </div>
            
            <div class="feature">
                <h4>‚ö° Workflows</h4>
                <p>Event-driven pipelines combining agents, data sources, and tools. More flexible than graph-based approaches.</p>
            </div>
            
            <h2>5-Line Quickstart</h2>
            <pre><code>from llama_index.core import VectorStoreIndex, SimpleDirectoryReader

# Load documents from a folder
documents = SimpleDirectoryReader("data").load_data()

# Create vector index
index = VectorStoreIndex.from_documents(documents)

# Query
query_engine = index.as_query_engine()
response = query_engine.query("What is this about?")
print(response)</code></pre>
            
            <h2>TypeScript Support</h2>
            <pre><code>import { VectorStoreIndex, SimpleDirectoryReader } from "llamaindex";

const documents = await new SimpleDirectoryReader().loadData("./data");
const index = await VectorStoreIndex.fromDocuments(documents);
const queryEngine = index.asQueryEngine();
const response = await queryEngine.query("What is this about?");</code></pre>
            
            <h2>Key Use Cases</h2>
            <ul>
                <li><strong>RAG / Q&A:</strong> Answer questions over documents</li>
                <li><strong>Chatbots:</strong> Conversational AI with memory</li>
                <li><strong>Document extraction:</strong> Parse and structure unstructured data</li>
                <li><strong>Autonomous agents:</strong> Research and task completion</li>
                <li><strong>Multi-modal:</strong> Combine text, images, and other data</li>
            </ul>
            
            <h2>LlamaCloud (Managed Service)</h2>
            <ul>
                <li><strong>LlamaParse:</strong> Best-in-class document parsing (tables, images, complex layouts)</li>
                <li><strong>LlamaExtract:</strong> Schema-based data extraction</li>
                <li><strong>Managed Indexing:</strong> Connect data sources, auto-sync, production-ready retrieval</li>
            </ul>
            
            <h2>Key Documentation Links</h2>
            <div class="links">
                <a href="https://docs.llamaindex.ai/en/stable/getting_started/concepts/" target="_blank">üìñ Core Concepts</a>
                <a href="https://docs.llamaindex.ai/en/stable/use_cases/q_and_a/" target="_blank">‚ùì RAG / Q&A Guide</a>
                <a href="https://docs.llamaindex.ai/en/stable/module_guides/loading/" target="_blank">üì• Data Loading</a>
                <a href="https://docs.llamaindex.ai/en/stable/module_guides/indexing/" target="_blank">üìä Indexing</a>
                <a href="https://docs.llamaindex.ai/en/stable/module_guides/querying/" target="_blank">üîç Querying</a>
                <a href="https://llamahub.ai/" target="_blank">üîå LlamaHub Integrations</a>
            </div>
            
            <h2>LlamaIndex vs Building from Scratch</h2>
            <ul>
                <li><strong>Build from scratch first:</strong> Understand embeddings, chunking, vector search fundamentals</li>
                <li><strong>Use LlamaIndex when:</strong> You need production features (agents, workflows, multiple data sources)</li>
                <li><strong>Best practice:</strong> Start simple, add LlamaIndex when complexity grows</li>
            </ul>
        </div>
    </div>
</body>
</html>
