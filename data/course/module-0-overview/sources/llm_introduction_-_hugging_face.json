{
  "name": "LLM Introduction - Hugging Face",
  "url": "https://huggingface.co/docs/transformers/llm_tutorial",
  "pages": [
    {
      "url": "https://huggingface.co/docs/transformers/llm_tutorial",
      "title": "LLM Introduction - Hugging Face",
      "content_html": "<main class=\"flex flex-1 flex-col\"><div class=\"relative lg:flex\" id=\"hf-doc-container\"><div class=\"sticky top-0 z-20 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props='{\"chapters\":[{\"title\":\"Get started\",\"isExpanded\":true,\"sections\":[{\"title\":\"Transformers\",\"isExpanded\":true,\"id\":\"index\",\"url\":\"/docs/transformers/index\"},{\"title\":\"Installation\",\"isExpanded\":true,\"id\":\"installation\",\"url\":\"/docs/transformers/installation\"},{\"title\":\"Quickstart\",\"isExpanded\":true,\"id\":\"quicktour\",\"url\":\"/docs/transformers/quicktour\"}]},{\"title\":\"Base classes\",\"isExpanded\":false,\"sections\":[{\"title\":\"Models\",\"isExpanded\":false,\"sections\":[{\"title\":\"Loading models\",\"id\":\"models\",\"url\":\"/docs/transformers/models\"},{\"title\":\"Customizing models\",\"id\":\"custom_models\",\"url\":\"/docs/transformers/custom_models\"},{\"title\":\"Customizing model components\",\"id\":\"how_to_hack_models\",\"url\":\"/docs/transformers/how_to_hack_models\"},{\"title\":\"Sharing\",\"id\":\"model_sharing\",\"url\":\"/docs/transformers/model_sharing\"},{\"title\":\"Contributing a new model to Transformers\",\"id\":\"modular_transformers\",\"url\":\"/docs/transformers/modular_transformers\"},{\"title\":\"Legacy model contribution\",\"id\":\"add_new_model\",\"url\":\"/docs/transformers/add_new_model\"},{\"title\":\"Documenting a model\",\"id\":\"auto_docstring\",\"url\":\"/docs/transformers/auto_docstring\"}]},{\"title\":\"Preprocessors\",\"isExpanded\":false,\"sections\":[{\"title\":\"Tokenizers\",\"id\":\"fast_tokenizers\",\"url\":\"/docs/transformers/fast_tokenizers\"},{\"title\":\"Image processors\",\"id\":\"image_processors\",\"url\":\"/docs/transformers/image_processors\"},{\"title\":\"Video processors\",\"id\":\"video_processors\",\"url\":\"/docs/transformers/video_processors\"},{\"title\":\"Backbones\",\"id\":\"backbones\",\"url\":\"/docs/transformers/backbones\"},{\"title\":\"Feature extractors\",\"id\":\"feature_extractors\",\"url\":\"/docs/transformers/feature_extractors\"},{\"title\":\"Processors\",\"id\":\"processors\",\"url\":\"/docs/transformers/processors\"},{\"title\":\"Summary of the tokenizers\",\"id\":\"tokenizer_summary\",\"url\":\"/docs/transformers/tokenizer_summary\"},{\"title\":\"Padding and truncation\",\"id\":\"pad_truncation\",\"url\":\"/docs/transformers/pad_truncation\"}]}]},{\"title\":\"Inference\",\"isExpanded\":true,\"sections\":[{\"title\":\"Pipeline API\",\"isExpanded\":false,\"sections\":[{\"title\":\"Pipeline\",\"id\":\"pipeline_tutorial\",\"url\":\"/docs/transformers/pipeline_tutorial\"},{\"title\":\"Machine learning apps\",\"id\":\"pipeline_gradio\",\"url\":\"/docs/transformers/pipeline_gradio\"},{\"title\":\"Web server inference\",\"id\":\"pipeline_webserver\",\"url\":\"/docs/transformers/pipeline_webserver\"},{\"title\":\"Adding a new pipeline\",\"id\":\"add_new_pipeline\",\"url\":\"/docs/transformers/add_new_pipeline\"}]},{\"title\":\"Generate API\",\"isExpanded\":true,\"sections\":[{\"title\":\"Text generation\",\"isExpanded\":true,\"id\":\"llm_tutorial\",\"url\":\"/docs/transformers/llm_tutorial\"},{\"title\":\"Decoding methods\",\"id\":\"generation_strategies\",\"url\":\"/docs/transformers/generation_strategies\"},{\"title\":\"Generation features\",\"id\":\"generation_features\",\"url\":\"/docs/transformers/generation_features\"},{\"title\":\"Prompt engineering\",\"id\":\"tasks/prompting\",\"url\":\"/docs/transformers/tasks/prompting\"},{\"title\":\"Perplexity of fixed-length models\",\"id\":\"perplexity\",\"url\":\"/docs/transformers/perplexity\"}]},{\"title\":\"Optimization\",\"isExpanded\":false,\"sections\":[{\"title\":\"Attention backends\",\"id\":\"attention_interface\",\"url\":\"/docs/transformers/attention_interface\"},{\"title\":\"Continuous batching\",\"id\":\"continuous_batching\",\"url\":\"/docs/transformers/continuous_batching\"},{\"title\":\"Kernels in transformers\",\"id\":\"kernel_doc/overview\",\"url\":\"/docs/transformers/kernel_doc/overview\"},{\"title\":\"torch.compile\",\"id\":\"perf_torch_compile\",\"url\":\"/docs/transformers/perf_torch_compile\"},{\"title\":\"GPU\",\"id\":\"perf_infer_gpu_one\",\"url\":\"/docs/transformers/perf_infer_gpu_one\"},{\"title\":\"Distributed inference\",\"id\":\"perf_infer_gpu_multi\",\"url\":\"/docs/transformers/perf_infer_gpu_multi\"},{\"title\":\"CPU\",\"id\":\"perf_infer_cpu\",\"url\":\"/docs/transformers/perf_infer_cpu\"},{\"title\":\"Optimizing inference\",\"id\":\"llm_optims\",\"url\":\"/docs/transformers/llm_optims\"},{\"title\":\"Caching\",\"id\":\"cache_explanation\",\"url\":\"/docs/transformers/cache_explanation\"},{\"title\":\"KV cache strategies\",\"id\":\"kv_cache\",\"url\":\"/docs/transformers/kv_cache\"},{\"title\":\"Getting the most out of LLMs\",\"id\":\"llm_tutorial_optimization\",\"url\":\"/docs/transformers/llm_tutorial_optimization\"}]},{\"title\":\"Chat with models\",\"isExpanded\":false,\"sections\":[{\"title\":\"Chat basics\",\"id\":\"conversations\",\"url\":\"/docs/transformers/conversations\"},{\"title\":\"Chat templates\",\"id\":\"chat_templating\",\"url\":\"/docs/transformers/chat_templating\"},{\"title\":\"Multimodal chat templates\",\"id\":\"chat_templating_multimodal\",\"url\":\"/docs/transformers/chat_templating_multimodal\"},{\"title\":\"Tool use\",\"id\":\"chat_extras\",\"url\":\"/docs/transformers/chat_extras\"},{\"title\":\"Writing a chat template\",\"id\":\"chat_templating_writing\",\"url\":\"/docs/transformers/chat_templating_writing\"}]},{\"title\":\"Serving\",\"isExpanded\":false,\"sections\":[{\"title\":\"Serving LLMs, VLMs, and other chat-based models\",\"id\":\"serving\",\"url\":\"/docs/transformers/serving\"},{\"title\":\"Jan\",\"id\":\"jan\",\"url\":\"/docs/transformers/jan\"},{\"title\":\"Cursor\",\"id\":\"cursor\",\"url\":\"/docs/transformers/cursor\"},{\"title\":\"Tiny-Agents CLI and MCP tools\",\"id\":\"tiny_agents\",\"url\":\"/docs/transformers/tiny_agents\"},{\"title\":\"Open WebUI\",\"id\":\"open_webui\",\"url\":\"/docs/transformers/open_webui\"}]},{\"title\":\"Agents\",\"id\":\"agents\",\"url\":\"/docs/transformers/agents\"},{\"title\":\"Tools\",\"id\":\"tools\",\"url\":\"/docs/transformers/tools\"},{\"title\":\"Transformers as modeling backend\",\"id\":\"transformers_as_backend\",\"url\":\"/docs/transformers/transformers_as_backend\"}]},{\"title\":\"Training\",\"isExpanded\":false,\"sections\":[{\"title\":\"Trainer API\",\"isExpanded\":false,\"sections\":[{\"title\":\"Trainer\",\"id\":\"trainer\",\"url\":\"/docs/transformers/trainer\"},{\"title\":\"Fine-tuning\",\"id\":\"training\",\"url\":\"/docs/transformers/training\"},{\"title\":\"Optimizers\",\"id\":\"optimizers\",\"url\":\"/docs/transformers/optimizers\"},{\"title\":\"Hyperparameter search\",\"id\":\"hpo_train\",\"url\":\"/docs/transformers/hpo_train\"}]},{\"title\":\"Distributed training\",\"isExpanded\":false,\"sections\":[{\"title\":\"Accelerator selection\",\"id\":\"accelerator_selection\",\"url\":\"/docs/transformers/accelerator_selection\"},{\"title\":\"Accelerate\",\"id\":\"accelerate\",\"url\":\"/docs/transformers/accelerate\"},{\"title\":\"FullyShardedDataParallel\",\"id\":\"fsdp\",\"url\":\"/docs/transformers/fsdp\"},{\"title\":\"DeepSpeed\",\"id\":\"deepspeed\",\"url\":\"/docs/transformers/deepspeed\"},{\"title\":\"Multi-GPU debugging\",\"id\":\"debugging\",\"url\":\"/docs/transformers/debugging\"},{\"title\":\"Distributed CPUs\",\"id\":\"perf_train_cpu_many\",\"url\":\"/docs/transformers/perf_train_cpu_many\"},{\"title\":\"Parallelism methods\",\"id\":\"perf_train_gpu_many\",\"url\":\"/docs/transformers/perf_train_gpu_many\"}]},{\"title\":\"Hardware\",\"isExpanded\":false,\"sections\":[{\"title\":\"GPU\",\"id\":\"perf_train_gpu_one\",\"url\":\"/docs/transformers/perf_train_gpu_one\"},{\"title\":\"CPU\",\"id\":\"perf_train_cpu\",\"url\":\"/docs/transformers/perf_train_cpu\"},{\"title\":\"Apple Silicon\",\"id\":\"perf_train_special\",\"url\":\"/docs/transformers/perf_train_special\"},{\"title\":\"Intel Gaudi\",\"id\":\"perf_train_gaudi\",\"url\":\"/docs/transformers/perf_train_gaudi\"},{\"title\":\"Build your own machine\",\"id\":\"perf_hardware\",\"url\":\"/docs/transformers/perf_hardware\"}]},{\"title\":\"PEFT\",\"id\":\"peft\",\"url\":\"/docs/transformers/peft\"},{\"title\":\"Model training anatomy\",\"id\":\"model_memory_anatomy\",\"url\":\"/docs/transformers/model_memory_anatomy\"}]},{\"title\":\"Quantization\",\"isExpanded\":false,\"sections\":[{\"title\":\"Overview\",\"id\":\"quantization/overview\",\"url\":\"/docs/transformers/quantization/overview\"},{\"title\":\"Selecting a quantization method\",\"id\":\"quantization/selecting\",\"url\":\"/docs/transformers/quantization/selecting\"},{\"title\":\"Quantization concepts\",\"id\":\"quantization/concept_guide\",\"url\":\"/docs/transformers/quantization/concept_guide\"},{\"title\":\"AQLM\",\"id\":\"quantization/aqlm\",\"url\":\"/docs/transformers/quantization/aqlm\"},{\"title\":\"AutoRound\",\"id\":\"quantization/auto_round\",\"url\":\"/docs/transformers/quantization/auto_round\"},{\"title\":\"AWQ\",\"id\":\"quantization/awq\",\"url\":\"/docs/transformers/quantization/awq\"},{\"title\":\"BitNet\",\"id\":\"quantization/bitnet\",\"url\":\"/docs/transformers/quantization/bitnet\"},{\"title\":\"bitsandbytes\",\"id\":\"quantization/bitsandbytes\",\"url\":\"/docs/transformers/quantization/bitsandbytes\"},{\"title\":\"compressed-tensors\",\"id\":\"quantization/compressed_tensors\",\"url\":\"/docs/transformers/quantization/compressed_tensors\"},{\"title\":\"EETQ\",\"id\":\"quantization/eetq\",\"url\":\"/docs/transformers/quantization/eetq\"},{\"title\":\"FBGEMM\",\"id\":\"quantization/fbgemm_fp8\",\"url\":\"/docs/transformers/quantization/fbgemm_fp8\"},{\"title\":\"Fine-grained FP8\",\"id\":\"quantization/finegrained_fp8\",\"url\":\"/docs/transformers/quantization/finegrained_fp8\"},{\"title\":\"FP-Quant\",\"id\":\"quantization/fp_quant\",\"url\":\"/docs/transformers/quantization/fp_quant\"},{\"title\":\"GGUF\",\"id\":\"gguf\",\"url\":\"/docs/transformers/gguf\"},{\"title\":\"GPTQ\",\"id\":\"quantization/gptq\",\"url\":\"/docs/transformers/quantization/gptq\"},{\"title\":\"HIGGS\",\"id\":\"quantization/higgs\",\"url\":\"/docs/transformers/quantization/higgs\"},{\"title\":\"HQQ\",\"id\":\"quantization/hqq\",\"url\":\"/docs/transformers/quantization/hqq\"},{\"title\":\"MXFP4\",\"id\":\"quantization/mxfp4\",\"url\":\"/docs/transformers/quantization/mxfp4\"},{\"title\":\"Optimum\",\"id\":\"quantization/optimum\",\"url\":\"/docs/transformers/quantization/optimum\"},{\"title\":\"Quanto\",\"id\":\"quantization/quanto\",\"url\":\"/docs/transformers/quantization/quanto\"},{\"title\":\"Quark\",\"id\":\"quantization/quark\",\"url\":\"/docs/transformers/quantization/quark\"},{\"title\":\"torchao\",\"id\":\"quantization/torchao\",\"url\":\"/docs/transformers/quantization/torchao\"},{\"title\":\"SpQR\",\"id\":\"quantization/spqr\",\"url\":\"/docs/transformers/quantization/spqr\"},{\"title\":\"VPTQ\",\"id\":\"quantization/vptq\",\"url\":\"/docs/transformers/quantization/vptq\"},{\"title\":\"Contribute\",\"id\":\"quantization/contribute\",\"url\":\"/docs/transformers/quantization/contribute\"}]},{\"title\":\"Export to production\",\"isExpanded\":false,\"sections\":[{\"title\":\"ONNX\",\"id\":\"serialization\",\"url\":\"/docs/transformers/serialization\"},{\"title\":\"ExecuTorch\",\"id\":\"executorch\",\"url\":\"/docs/transformers/executorch\"}]},{\"title\":\"Resources\",\"isExpanded\":false,\"sections\":[{\"title\":\"Task recipes\",\"isExpanded\":false,\"sections\":[{\"title\":\"Natural language processing\",\"isExpanded\":false,\"sections\":[{\"title\":\"Text classification\",\"id\":\"tasks/sequence_classification\",\"url\":\"/docs/transformers/tasks/sequence_classification\"},{\"title\":\"Token classification\",\"id\":\"tasks/token_classification\",\"url\":\"/docs/transformers/tasks/token_classification\"},{\"title\":\"Question answering\",\"id\":\"tasks/question_answering\",\"url\":\"/docs/transformers/tasks/question_answering\"},{\"title\":\"Causal language modeling\",\"id\":\"tasks/language_modeling\",\"url\":\"/docs/transformers/tasks/language_modeling\"},{\"title\":\"Masked language modeling\",\"id\":\"tasks/masked_language_modeling\",\"url\":\"/docs/transformers/tasks/masked_language_modeling\"},{\"title\":\"Translation\",\"id\":\"tasks/translation\",\"url\":\"/docs/transformers/tasks/translation\"},{\"title\":\"Summarization\",\"id\":\"tasks/summarization\",\"url\":\"/docs/transformers/tasks/summarization\"},{\"title\":\"Multiple choice\",\"id\":\"tasks/multiple_choice\",\"url\":\"/docs/transformers/tasks/multiple_choice\"}]},{\"title\":\"Audio\",\"isExpanded\":false,\"sections\":[{\"title\":\"Audio classification\",\"id\":\"tasks/audio_classification\",\"url\":\"/docs/transformers/tasks/audio_classification\"},{\"title\":\"Automatic speech recognition\",\"id\":\"tasks/asr\",\"url\":\"/docs/transformers/tasks/asr\"}]},{\"title\":\"Computer vision\",\"isExpanded\":false,\"sections\":[{\"title\":\"Image classification\",\"id\":\"tasks/image_classification\",\"url\":\"/docs/transformers/tasks/image_classification\"},{\"title\":\"Image segmentation\",\"id\":\"tasks/semantic_segmentation\",\"url\":\"/docs/transformers/tasks/semantic_segmentation\"},{\"title\":\"Video classification\",\"id\":\"tasks/video_classification\",\"url\":\"/docs/transformers/tasks/video_classification\"},{\"title\":\"Object detection\",\"id\":\"tasks/object_detection\",\"url\":\"/docs/transformers/tasks/object_detection\"},{\"title\":\"Zero-shot object detection\",\"id\":\"tasks/zero_shot_object_detection\",\"url\":\"/docs/transformers/tasks/zero_shot_object_detection\"},{\"title\":\"Zero-shot image classification\",\"id\":\"tasks/zero_shot_image_classification\",\"url\":\"/docs/transformers/tasks/zero_shot_image_classification\"},{\"title\":\"Depth estimation\",\"id\":\"tasks/monocular_depth_estimation\",\"url\":\"/docs/transformers/tasks/monocular_depth_estimation\"},{\"title\":\"Image-to-Image\",\"id\":\"tasks/image_to_image\",\"url\":\"/docs/transformers/tasks/image_to_image\"},{\"title\":\"Image Feature Extraction\",\"id\":\"tasks/image_feature_extraction\",\"url\":\"/docs/transformers/tasks/image_feature_extraction\"},{\"title\":\"Mask Generation\",\"id\":\"tasks/mask_generation\",\"url\":\"/docs/transformers/tasks/mask_generation\"},{\"title\":\"Keypoint detection\",\"id\":\"tasks/keypoint_detection\",\"url\":\"/docs/transformers/tasks/keypoint_detection\"},{\"title\":\"Knowledge Distillation for Computer Vision\",\"id\":\"tasks/knowledge_distillation_for_image_classification\",\"url\":\"/docs/transformers/tasks/knowledge_distillation_for_image_classification\"},{\"title\":\"Keypoint matching\",\"id\":\"tasks/keypoint_matching\",\"url\":\"/docs/transformers/tasks/keypoint_matching\"},{\"title\":\"Training vision models using Backbone API\",\"id\":\"tasks/training_vision_backbone\",\"url\":\"/docs/transformers/tasks/training_vision_backbone\"}]},{\"title\":\"Multimodal\",\"isExpanded\":false,\"sections\":[{\"title\":\"Image captioning\",\"id\":\"tasks/image_captioning\",\"url\":\"/docs/transformers/tasks/image_captioning\"},{\"title\":\"Document Question Answering\",\"id\":\"tasks/document_question_answering\",\"url\":\"/docs/transformers/tasks/document_question_answering\"},{\"title\":\"Visual Question Answering\",\"id\":\"tasks/visual_question_answering\",\"url\":\"/docs/transformers/tasks/visual_question_answering\"},{\"title\":\"Text to speech\",\"id\":\"tasks/text-to-speech\",\"url\":\"/docs/transformers/tasks/text-to-speech\"},{\"title\":\"Image tasks with IDEFICS\",\"id\":\"tasks/idefics\",\"url\":\"/docs/transformers/tasks/idefics\"},{\"title\":\"Image-text-to-text\",\"id\":\"tasks/image_text_to_text\",\"url\":\"/docs/transformers/tasks/image_text_to_text\"},{\"title\":\"Any-to-any\",\"id\":\"tasks/any_to_any\",\"url\":\"/docs/transformers/tasks/any_to_any\"},{\"title\":\"Video-text-to-text\",\"id\":\"tasks/video_text_to_text\",\"url\":\"/docs/transformers/tasks/video_text_to_text\"},{\"title\":\"Visual Document Retrieval\",\"id\":\"tasks/visual_document_retrieval\",\"url\":\"/docs/transformers/tasks/visual_document_retrieval\"}]}]},{\"title\":\"Training scripts\",\"id\":\"run_scripts\",\"url\":\"/docs/transformers/run_scripts\"},{\"title\":\"Glossary\",\"id\":\"glossary\",\"url\":\"/docs/transformers/glossary\"},{\"title\":\"Philosophy\",\"id\":\"philosophy\",\"url\":\"/docs/transformers/philosophy\"},{\"title\":\"Models Timeline\",\"id\":\"models_timeline\",\"url\":\"/docs/transformers/models_timeline\"},{\"title\":\"Notebooks with examples\",\"id\":\"notebooks\",\"url\":\"/docs/transformers/notebooks\"},{\"title\":\"Community resources\",\"id\":\"community\",\"url\":\"/docs/transformers/community\"},{\"title\":\"Troubleshoot\",\"id\":\"troubleshooting\",\"url\":\"/docs/transformers/troubleshooting\"}]},{\"title\":\"Contribute\",\"isExpanded\":false,\"sections\":[{\"title\":\"Contribute to Transformers\",\"id\":\"contributing\",\"url\":\"/docs/transformers/contributing\"},{\"title\":\"Transformers model tests\",\"id\":\"testing\",\"url\":\"/docs/transformers/testing\"},{\"title\":\"Pull request checks\",\"id\":\"pr_checks\",\"url\":\"/docs/transformers/pr_checks\"}]},{\"title\":\"API\",\"isExpanded\":false,\"sections\":[{\"title\":\"Main Classes\",\"isExpanded\":false,\"sections\":[{\"title\":\"Auto Classes\",\"id\":\"model_doc/auto\",\"url\":\"/docs/transformers/model_doc/auto\"},{\"title\":\"Backbones\",\"id\":\"main_classes/backbones\",\"url\":\"/docs/transformers/main_classes/backbones\"},{\"title\":\"Callbacks\",\"id\":\"main_classes/callback\",\"url\":\"/docs/transformers/main_classes/callback\"},{\"title\":\"Configuration\",\"id\":\"main_classes/configuration\",\"url\":\"/docs/transformers/main_classes/configuration\"},{\"title\":\"Data Collator\",\"id\":\"main_classes/data_collator\",\"url\":\"/docs/transformers/main_classes/data_collator\"},{\"title\":\"Logging\",\"id\":\"main_classes/logging\",\"url\":\"/docs/transformers/main_classes/logging\"},{\"title\":\"Models\",\"id\":\"main_classes/model\",\"url\":\"/docs/transformers/main_classes/model\"},{\"title\":\"Text Generation\",\"id\":\"main_classes/text_generation\",\"url\":\"/docs/transformers/main_classes/text_generation\"},{\"title\":\"Optimization\",\"id\":\"main_classes/optimizer_schedules\",\"url\":\"/docs/transformers/main_classes/optimizer_schedules\"},{\"title\":\"Model outputs\",\"id\":\"main_classes/output\",\"url\":\"/docs/transformers/main_classes/output\"},{\"title\":\"PEFT\",\"id\":\"main_classes/peft\",\"url\":\"/docs/transformers/main_classes/peft\"},{\"title\":\"Pipelines\",\"id\":\"main_classes/pipelines\",\"url\":\"/docs/transformers/main_classes/pipelines\"},{\"title\":\"Processors\",\"id\":\"main_classes/processors\",\"url\":\"/docs/transformers/main_classes/processors\"},{\"title\":\"Quantization\",\"id\":\"main_classes/quantization\",\"url\":\"/docs/transformers/main_classes/quantization\"},{\"title\":\"Tokenizer\",\"id\":\"main_classes/tokenizer\",\"url\":\"/docs/transformers/main_classes/tokenizer\"},{\"title\":\"Trainer\",\"id\":\"main_classes/trainer\",\"url\":\"/docs/transformers/main_classes/trainer\"},{\"title\":\"DeepSpeed\",\"id\":\"main_classes/deepspeed\",\"url\":\"/docs/transformers/main_classes/deepspeed\"},{\"title\":\"ExecuTorch\",\"id\":\"main_classes/executorch\",\"url\":\"/docs/transformers/main_classes/executorch\"},{\"title\":\"Feature Extractor\",\"id\":\"main_classes/feature_extractor\",\"url\":\"/docs/transformers/main_classes/feature_extractor\"},{\"title\":\"Image Processor\",\"id\":\"main_classes/image_processor\",\"url\":\"/docs/transformers/main_classes/image_processor\"},{\"title\":\"Video Processor\",\"id\":\"main_classes/video_processor\",\"url\":\"/docs/transformers/main_classes/video_processor\"},{\"title\":\"Kernels\",\"id\":\"main_classes/kernels\",\"url\":\"/docs/transformers/main_classes/kernels\"}]},{\"title\":\"Models\",\"isExpanded\":false,\"sections\":[{\"title\":\"Text models\",\"isExpanded\":false,\"sections\":[{\"title\":\"AFMoE\",\"id\":\"model_doc/afmoe\",\"url\":\"/docs/transformers/model_doc/afmoe\"},{\"title\":\"ALBERT\",\"id\":\"model_doc/albert\",\"url\":\"/docs/transformers/model_doc/albert\"},{\"title\":\"Apertus\",\"id\":\"model_doc/apertus\",\"url\":\"/docs/transformers/model_doc/apertus\"},{\"title\":\"Arcee\",\"id\":\"model_doc/arcee\",\"url\":\"/docs/transformers/model_doc/arcee\"},{\"title\":\"Bamba\",\"id\":\"model_doc/bamba\",\"url\":\"/docs/transformers/model_doc/bamba\"},{\"title\":\"BART\",\"id\":\"model_doc/bart\",\"url\":\"/docs/transformers/model_doc/bart\"},{\"title\":\"BARThez\",\"id\":\"model_doc/barthez\",\"url\":\"/docs/transformers/model_doc/barthez\"},{\"title\":\"BARTpho\",\"id\":\"model_doc/bartpho\",\"url\":\"/docs/transformers/model_doc/bartpho\"},{\"title\":\"BERT\",\"id\":\"model_doc/bert\",\"url\":\"/docs/transformers/model_doc/bert\"},{\"title\":\"BertGeneration\",\"id\":\"model_doc/bert-generation\",\"url\":\"/docs/transformers/model_doc/bert-generation\"},{\"title\":\"BertJapanese\",\"id\":\"model_doc/bert-japanese\",\"url\":\"/docs/transformers/model_doc/bert-japanese\"},{\"title\":\"BERTweet\",\"id\":\"model_doc/bertweet\",\"url\":\"/docs/transformers/model_doc/bertweet\"},{\"title\":\"BigBird\",\"id\":\"model_doc/big_bird\",\"url\":\"/docs/transformers/model_doc/big_bird\"},{\"title\":\"BigBirdPegasus\",\"id\":\"model_doc/bigbird_pegasus\",\"url\":\"/docs/transformers/model_doc/bigbird_pegasus\"},{\"title\":\"BioGpt\",\"id\":\"model_doc/biogpt\",\"url\":\"/docs/transformers/model_doc/biogpt\"},{\"title\":\"BitNet\",\"id\":\"model_doc/bitnet\",\"url\":\"/docs/transformers/model_doc/bitnet\"},{\"title\":\"Blenderbot\",\"id\":\"model_doc/blenderbot\",\"url\":\"/docs/transformers/model_doc/blenderbot\"},{\"title\":\"Blenderbot Small\",\"id\":\"model_doc/blenderbot-small\",\"url\":\"/docs/transformers/model_doc/blenderbot-small\"},{\"title\":\"BLOOM\",\"id\":\"model_doc/bloom\",\"url\":\"/docs/transformers/model_doc/bloom\"},{\"title\":\"BLT\",\"id\":\"model_doc/blt\",\"url\":\"/docs/transformers/model_doc/blt\"},{\"title\":\"ByT5\",\"id\":\"model_doc/byt5\",\"url\":\"/docs/transformers/model_doc/byt5\"},{\"title\":\"CamemBERT\",\"id\":\"model_doc/camembert\",\"url\":\"/docs/transformers/model_doc/camembert\"},{\"title\":\"CANINE\",\"id\":\"model_doc/canine\",\"url\":\"/docs/transformers/model_doc/canine\"},{\"title\":\"CodeGen\",\"id\":\"model_doc/codegen\",\"url\":\"/docs/transformers/model_doc/codegen\"},{\"title\":\"CodeLlama\",\"id\":\"model_doc/code_llama\",\"url\":\"/docs/transformers/model_doc/code_llama\"},{\"title\":\"Cohere\",\"id\":\"model_doc/cohere\",\"url\":\"/docs/transformers/model_doc/cohere\"},{\"title\":\"Cohere2\",\"id\":\"model_doc/cohere2\",\"url\":\"/docs/transformers/model_doc/cohere2\"},{\"title\":\"ConvBERT\",\"id\":\"model_doc/convbert\",\"url\":\"/docs/transformers/model_doc/convbert\"},{\"title\":\"CPM\",\"id\":\"model_doc/cpm\",\"url\":\"/docs/transformers/model_doc/cpm\"},{\"title\":\"CPMANT\",\"id\":\"model_doc/cpmant\",\"url\":\"/docs/transformers/model_doc/cpmant\"},{\"title\":\"CTRL\",\"id\":\"model_doc/ctrl\",\"url\":\"/docs/transformers/model_doc/ctrl\"},{\"title\":\"DBRX\",\"id\":\"model_doc/dbrx\",\"url\":\"/docs/transformers/model_doc/dbrx\"},{\"title\":\"DeBERTa\",\"id\":\"model_doc/deberta\",\"url\":\"/docs/transformers/model_doc/deberta\"},{\"title\":\"DeBERTa-v2\",\"id\":\"model_doc/deberta-v2\",\"url\":\"/docs/transformers/model_doc/deberta-v2\"},{\"title\":\"DeepSeek-V2\",\"id\":\"model_doc/deepseek_v2\",\"url\":\"/docs/transformers/model_doc/deepseek_v2\"},{\"title\":\"DeepSeek-V3\",\"id\":\"model_doc/deepseek_v3\",\"url\":\"/docs/transformers/model_doc/deepseek_v3\"},{\"title\":\"DialoGPT\",\"id\":\"model_doc/dialogpt\",\"url\":\"/docs/transformers/model_doc/dialogpt\"},{\"title\":\"DiffLlama\",\"id\":\"model_doc/diffllama\",\"url\":\"/docs/transformers/model_doc/diffllama\"},{\"title\":\"DistilBERT\",\"id\":\"model_doc/distilbert\",\"url\":\"/docs/transformers/model_doc/distilbert\"},{\"title\":\"Doge\",\"id\":\"model_doc/doge\",\"url\":\"/docs/transformers/model_doc/doge\"},{\"title\":\"dots1\",\"id\":\"model_doc/dots1\",\"url\":\"/docs/transformers/model_doc/dots1\"},{\"title\":\"DPR\",\"id\":\"model_doc/dpr\",\"url\":\"/docs/transformers/model_doc/dpr\"},{\"title\":\"ELECTRA\",\"id\":\"model_doc/electra\",\"url\":\"/docs/transformers/model_doc/electra\"},{\"title\":\"Encoder Decoder Models\",\"id\":\"model_doc/encoder-decoder\",\"url\":\"/docs/transformers/model_doc/encoder-decoder\"},{\"title\":\"ERNIE\",\"id\":\"model_doc/ernie\",\"url\":\"/docs/transformers/model_doc/ernie\"},{\"title\":\"Ernie4_5\",\"id\":\"model_doc/ernie4_5\",\"url\":\"/docs/transformers/model_doc/ernie4_5\"},{\"title\":\"Ernie4_5_MoE\",\"id\":\"model_doc/ernie4_5_moe\",\"url\":\"/docs/transformers/model_doc/ernie4_5_moe\"},{\"title\":\"ESM\",\"id\":\"model_doc/esm\",\"url\":\"/docs/transformers/model_doc/esm\"},{\"title\":\"EXAONE-4.0\",\"id\":\"model_doc/exaone4\",\"url\":\"/docs/transformers/model_doc/exaone4\"},{\"title\":\"Falcon\",\"id\":\"model_doc/falcon\",\"url\":\"/docs/transformers/model_doc/falcon\"},{\"title\":\"Falcon3\",\"id\":\"model_doc/falcon3\",\"url\":\"/docs/transformers/model_doc/falcon3\"},{\"title\":\"FalconH1\",\"id\":\"model_doc/falcon_h1\",\"url\":\"/docs/transformers/model_doc/falcon_h1\"},{\"title\":\"FalconMamba\",\"id\":\"model_doc/falcon_mamba\",\"url\":\"/docs/transformers/model_doc/falcon_mamba\"},{\"title\":\"FLAN-T5\",\"id\":\"model_doc/flan-t5\",\"url\":\"/docs/transformers/model_doc/flan-t5\"},{\"title\":\"FLAN-UL2\",\"id\":\"model_doc/flan-ul2\",\"url\":\"/docs/transformers/model_doc/flan-ul2\"},{\"title\":\"FlauBERT\",\"id\":\"model_doc/flaubert\",\"url\":\"/docs/transformers/model_doc/flaubert\"},{\"title\":\"FlexOlmo\",\"id\":\"model_doc/flex_olmo\",\"url\":\"/docs/transformers/model_doc/flex_olmo\"},{\"title\":\"FNet\",\"id\":\"model_doc/fnet\",\"url\":\"/docs/transformers/model_doc/fnet\"},{\"title\":\"FSMT\",\"id\":\"model_doc/fsmt\",\"url\":\"/docs/transformers/model_doc/fsmt\"},{\"title\":\"Funnel Transformer\",\"id\":\"model_doc/funnel\",\"url\":\"/docs/transformers/model_doc/funnel\"},{\"title\":\"Fuyu\",\"id\":\"model_doc/fuyu\",\"url\":\"/docs/transformers/model_doc/fuyu\"},{\"title\":\"Gemma\",\"id\":\"model_doc/gemma\",\"url\":\"/docs/transformers/model_doc/gemma\"},{\"title\":\"Gemma2\",\"id\":\"model_doc/gemma2\",\"url\":\"/docs/transformers/model_doc/gemma2\"},{\"title\":\"GLM\",\"id\":\"model_doc/glm\",\"url\":\"/docs/transformers/model_doc/glm\"},{\"title\":\"glm4\",\"id\":\"model_doc/glm4\",\"url\":\"/docs/transformers/model_doc/glm4\"},{\"title\":\"glm4_moe\",\"id\":\"model_doc/glm4_moe\",\"url\":\"/docs/transformers/model_doc/glm4_moe\"},{\"title\":\"GPT\",\"id\":\"model_doc/openai-gpt\",\"url\":\"/docs/transformers/model_doc/openai-gpt\"},{\"title\":\"GPT Neo\",\"id\":\"model_doc/gpt_neo\",\"url\":\"/docs/transformers/model_doc/gpt_neo\"},{\"title\":\"GPT NeoX\",\"id\":\"model_doc/gpt_neox\",\"url\":\"/docs/transformers/model_doc/gpt_neox\"},{\"title\":\"GPT NeoX Japanese\",\"id\":\"model_doc/gpt_neox_japanese\",\"url\":\"/docs/transformers/model_doc/gpt_neox_japanese\"},{\"title\":\"GPT-J\",\"id\":\"model_doc/gptj\",\"url\":\"/docs/transformers/model_doc/gptj\"},{\"title\":\"GPT2\",\"id\":\"model_doc/gpt2\",\"url\":\"/docs/transformers/model_doc/gpt2\"},{\"title\":\"GPTBigCode\",\"id\":\"model_doc/gpt_bigcode\",\"url\":\"/docs/transformers/model_doc/gpt_bigcode\"},{\"title\":\"GptOss\",\"id\":\"model_doc/gpt_oss\",\"url\":\"/docs/transformers/model_doc/gpt_oss\"},{\"title\":\"GPTSw3\",\"id\":\"model_doc/gpt-sw3\",\"url\":\"/docs/transformers/model_doc/gpt-sw3\"},{\"title\":\"Granite\",\"id\":\"model_doc/granite\",\"url\":\"/docs/transformers/model_doc/granite\"},{\"title\":\"GraniteMoe\",\"id\":\"model_doc/granitemoe\",\"url\":\"/docs/transformers/model_doc/granitemoe\"},{\"title\":\"GraniteMoeHybrid\",\"id\":\"model_doc/granitemoehybrid\",\"url\":\"/docs/transformers/model_doc/granitemoehybrid\"},{\"title\":\"GraniteMoeShared\",\"id\":\"model_doc/granitemoeshared\",\"url\":\"/docs/transformers/model_doc/granitemoeshared\"},{\"title\":\"Helium\",\"id\":\"model_doc/helium\",\"url\":\"/docs/transformers/model_doc/helium\"},{\"title\":\"HerBERT\",\"id\":\"model_doc/herbert\",\"url\":\"/docs/transformers/model_doc/herbert\"},{\"title\":\"HunYuanDenseV1\",\"id\":\"model_doc/hunyuan_v1_dense\",\"url\":\"/docs/transformers/model_doc/hunyuan_v1_dense\"},{\"title\":\"HunYuanMoEV1\",\"id\":\"model_doc/hunyuan_v1_moe\",\"url\":\"/docs/transformers/model_doc/hunyuan_v1_moe\"},{\"title\":\"I-BERT\",\"id\":\"model_doc/ibert\",\"url\":\"/docs/transformers/model_doc/ibert\"},{\"title\":\"Jamba\",\"id\":\"model_doc/jamba\",\"url\":\"/docs/transformers/model_doc/jamba\"},{\"title\":\"JetMoe\",\"id\":\"model_doc/jetmoe\",\"url\":\"/docs/transformers/model_doc/jetmoe\"},{\"title\":\"LED\",\"id\":\"model_doc/led\",\"url\":\"/docs/transformers/model_doc/led\"},{\"title\":\"LFM2\",\"id\":\"model_doc/lfm2\",\"url\":\"/docs/transformers/model_doc/lfm2\"},{\"title\":\"LFM2Moe\",\"id\":\"model_doc/lfm2_moe\",\"url\":\"/docs/transformers/model_doc/lfm2_moe\"},{\"title\":\"LLaMA\",\"id\":\"model_doc/llama\",\"url\":\"/docs/transformers/model_doc/llama\"},{\"title\":\"Llama2\",\"id\":\"model_doc/llama2\",\"url\":\"/docs/transformers/model_doc/llama2\"},{\"title\":\"Llama3\",\"id\":\"model_doc/llama3\",\"url\":\"/docs/transformers/model_doc/llama3\"},{\"title\":\"LongCatFlash\",\"id\":\"model_doc/longcat_flash\",\"url\":\"/docs/transformers/model_doc/longcat_flash\"},{\"title\":\"Longformer\",\"id\":\"model_doc/longformer\",\"url\":\"/docs/transformers/model_doc/longformer\"},{\"title\":\"LongT5\",\"id\":\"model_doc/longt5\",\"url\":\"/docs/transformers/model_doc/longt5\"},{\"title\":\"LUKE\",\"id\":\"model_doc/luke\",\"url\":\"/docs/transformers/model_doc/luke\"},{\"title\":\"M2M100\",\"id\":\"model_doc/m2m_100\",\"url\":\"/docs/transformers/model_doc/m2m_100\"},{\"title\":\"MADLAD-400\",\"id\":\"model_doc/madlad-400\",\"url\":\"/docs/transformers/model_doc/madlad-400\"},{\"title\":\"Mamba\",\"id\":\"model_doc/mamba\",\"url\":\"/docs/transformers/model_doc/mamba\"},{\"title\":\"Mamba2\",\"id\":\"model_doc/mamba2\",\"url\":\"/docs/transformers/model_doc/mamba2\"},{\"title\":\"MarianMT\",\"id\":\"model_doc/marian\",\"url\":\"/docs/transformers/model_doc/marian\"},{\"title\":\"MarkupLM\",\"id\":\"model_doc/markuplm\",\"url\":\"/docs/transformers/model_doc/markuplm\"},{\"title\":\"MBart and MBart-50\",\"id\":\"model_doc/mbart\",\"url\":\"/docs/transformers/model_doc/mbart\"},{\"title\":\"MegatronBERT\",\"id\":\"model_doc/megatron-bert\",\"url\":\"/docs/transformers/model_doc/megatron-bert\"},{\"title\":\"MegatronGPT2\",\"id\":\"model_doc/megatron_gpt2\",\"url\":\"/docs/transformers/model_doc/megatron_gpt2\"},{\"title\":\"MiniMax\",\"id\":\"model_doc/minimax\",\"url\":\"/docs/transformers/model_doc/minimax\"},{\"title\":\"Ministral\",\"id\":\"model_doc/ministral\",\"url\":\"/docs/transformers/model_doc/ministral\"},{\"title\":\"Ministral3\",\"id\":\"model_doc/ministral3\",\"url\":\"/docs/transformers/model_doc/ministral3\"},{\"title\":\"Mistral\",\"id\":\"model_doc/mistral\",\"url\":\"/docs/transformers/model_doc/mistral\"},{\"title\":\"Mixtral\",\"id\":\"model_doc/mixtral\",\"url\":\"/docs/transformers/model_doc/mixtral\"},{\"title\":\"mLUKE\",\"id\":\"model_doc/mluke\",\"url\":\"/docs/transformers/model_doc/mluke\"},{\"title\":\"MobileBERT\",\"id\":\"model_doc/mobilebert\",\"url\":\"/docs/transformers/model_doc/mobilebert\"},{\"title\":\"ModernBert\",\"id\":\"model_doc/modernbert\",\"url\":\"/docs/transformers/model_doc/modernbert\"},{\"title\":\"ModernBERTDecoder\",\"id\":\"model_doc/modernbert-decoder\",\"url\":\"/docs/transformers/model_doc/modernbert-decoder\"},{\"title\":\"MPNet\",\"id\":\"model_doc/mpnet\",\"url\":\"/docs/transformers/model_doc/mpnet\"},{\"title\":\"MPT\",\"id\":\"model_doc/mpt\",\"url\":\"/docs/transformers/model_doc/mpt\"},{\"title\":\"MRA\",\"id\":\"model_doc/mra\",\"url\":\"/docs/transformers/model_doc/mra\"},{\"title\":\"MT5\",\"id\":\"model_doc/mt5\",\"url\":\"/docs/transformers/model_doc/mt5\"},{\"title\":\"MVP\",\"id\":\"model_doc/mvp\",\"url\":\"/docs/transformers/model_doc/mvp\"},{\"title\":\"myt5\",\"id\":\"model_doc/myt5\",\"url\":\"/docs/transformers/model_doc/myt5\"},{\"title\":\"NanoChat\",\"id\":\"model_doc/nanochat\",\"url\":\"/docs/transformers/model_doc/nanochat\"},{\"title\":\"Nemotron\",\"id\":\"model_doc/nemotron\",\"url\":\"/docs/transformers/model_doc/nemotron\"},{\"title\":\"NLLB\",\"id\":\"model_doc/nllb\",\"url\":\"/docs/transformers/model_doc/nllb\"},{\"title\":\"NLLB-MoE\",\"id\":\"model_doc/nllb-moe\",\"url\":\"/docs/transformers/model_doc/nllb-moe\"},{\"title\":\"NystrÃ¶mformer\",\"id\":\"model_doc/nystromformer\",\"url\":\"/docs/transformers/model_doc/nystromformer\"},{\"title\":\"OLMo\",\"id\":\"model_doc/olmo\",\"url\":\"/docs/transformers/model_doc/olmo\"},{\"title\":\"OLMo2\",\"id\":\"model_doc/olmo2\",\"url\":\"/docs/transformers/model_doc/olmo2\"},{\"title\":\"Olmo3\",\"id\":\"model_doc/olmo3\",\"url\":\"/docs/transformers/model_doc/olmo3\"},{\"title\":\"OLMoE\",\"id\":\"model_doc/olmoe\",\"url\":\"/docs/transformers/model_doc/olmoe\"},{\"title\":\"OPT\",\"id\":\"model_doc/opt\",\"url\":\"/docs/transformers/model_doc/opt\"},{\"title\":\"Pegasus\",\"id\":\"model_doc/pegasus\",\"url\":\"/docs/transformers/model_doc/pegasus\"},{\"title\":\"PEGASUS-X\",\"id\":\"model_doc/pegasus_x\",\"url\":\"/docs/transformers/model_doc/pegasus_x\"},{\"title\":\"Persimmon\",\"id\":\"model_doc/persimmon\",\"url\":\"/docs/transformers/model_doc/persimmon\"},{\"title\":\"Phi\",\"id\":\"model_doc/phi\",\"url\":\"/docs/transformers/model_doc/phi\"},{\"title\":\"Phi-3\",\"id\":\"model_doc/phi3\",\"url\":\"/docs/transformers/model_doc/phi3\"},{\"title\":\"PhiMoE\",\"id\":\"model_doc/phimoe\",\"url\":\"/docs/transformers/model_doc/phimoe\"},{\"title\":\"PhoBERT\",\"id\":\"model_doc/phobert\",\"url\":\"/docs/transformers/model_doc/phobert\"},{\"title\":\"PLBart\",\"id\":\"model_doc/plbart\",\"url\":\"/docs/transformers/model_doc/plbart\"},{\"title\":\"ProphetNet\",\"id\":\"model_doc/prophetnet\",\"url\":\"/docs/transformers/model_doc/prophetnet\"},{\"title\":\"Qwen2\",\"id\":\"model_doc/qwen2\",\"url\":\"/docs/transformers/model_doc/qwen2\"},{\"title\":\"Qwen2MoE\",\"id\":\"model_doc/qwen2_moe\",\"url\":\"/docs/transformers/model_doc/qwen2_moe\"},{\"title\":\"Qwen3\",\"id\":\"model_doc/qwen3\",\"url\":\"/docs/transformers/model_doc/qwen3\"},{\"title\":\"Qwen3MoE\",\"id\":\"model_doc/qwen3_moe\",\"url\":\"/docs/transformers/model_doc/qwen3_moe\"},{\"title\":\"Qwen3Next\",\"id\":\"model_doc/qwen3_next\",\"url\":\"/docs/transformers/model_doc/qwen3_next\"},{\"title\":\"RAG\",\"id\":\"model_doc/rag\",\"url\":\"/docs/transformers/model_doc/rag\"},{\"title\":\"RecurrentGemma\",\"id\":\"model_doc/recurrent_gemma\",\"url\":\"/docs/transformers/model_doc/recurrent_gemma\"},{\"title\":\"Reformer\",\"id\":\"model_doc/reformer\",\"url\":\"/docs/transformers/model_doc/reformer\"},{\"title\":\"RemBERT\",\"id\":\"model_doc/rembert\",\"url\":\"/docs/transformers/model_doc/rembert\"},{\"title\":\"RoBERTa\",\"id\":\"model_doc/roberta\",\"url\":\"/docs/transformers/model_doc/roberta\"},{\"title\":\"RoBERTa-PreLayerNorm\",\"id\":\"model_doc/roberta-prelayernorm\",\"url\":\"/docs/transformers/model_doc/roberta-prelayernorm\"},{\"title\":\"RoCBert\",\"id\":\"model_doc/roc_bert\",\"url\":\"/docs/transformers/model_doc/roc_bert\"},{\"title\":\"RoFormer\",\"id\":\"model_doc/roformer\",\"url\":\"/docs/transformers/model_doc/roformer\"},{\"title\":\"RWKV\",\"id\":\"model_doc/rwkv\",\"url\":\"/docs/transformers/model_doc/rwkv\"},{\"title\":\"Seed-Oss\",\"id\":\"model_doc/seed_oss\",\"url\":\"/docs/transformers/model_doc/seed_oss\"},{\"title\":\"Splinter\",\"id\":\"model_doc/splinter\",\"url\":\"/docs/transformers/model_doc/splinter\"},{\"title\":\"SqueezeBERT\",\"id\":\"model_doc/squeezebert\",\"url\":\"/docs/transformers/model_doc/squeezebert\"},{\"title\":\"StableLm\",\"id\":\"model_doc/stablelm\",\"url\":\"/docs/transformers/model_doc/stablelm\"},{\"title\":\"Starcoder2\",\"id\":\"model_doc/starcoder2\",\"url\":\"/docs/transformers/model_doc/starcoder2\"},{\"title\":\"SwitchTransformers\",\"id\":\"model_doc/switch_transformers\",\"url\":\"/docs/transformers/model_doc/switch_transformers\"},{\"title\":\"T5\",\"id\":\"model_doc/t5\",\"url\":\"/docs/transformers/model_doc/t5\"},{\"title\":\"T5Gemma\",\"id\":\"model_doc/t5gemma\",\"url\":\"/docs/transformers/model_doc/t5gemma\"},{\"title\":\"T5Gemma2\",\"id\":\"model_doc/t5gemma2\",\"url\":\"/docs/transformers/model_doc/t5gemma2\"},{\"title\":\"T5v1.1\",\"id\":\"model_doc/t5v1.1\",\"url\":\"/docs/transformers/model_doc/t5v1.1\"},{\"title\":\"UL2\",\"id\":\"model_doc/ul2\",\"url\":\"/docs/transformers/model_doc/ul2\"},{\"title\":\"UMT5\",\"id\":\"model_doc/umt5\",\"url\":\"/docs/transformers/model_doc/umt5\"},{\"title\":\"VaultGemma\",\"id\":\"model_doc/vaultgemma\",\"url\":\"/docs/transformers/model_doc/vaultgemma\"},{\"title\":\"X-MOD\",\"id\":\"model_doc/xmod\",\"url\":\"/docs/transformers/model_doc/xmod\"},{\"title\":\"XGLM\",\"id\":\"model_doc/xglm\",\"url\":\"/docs/transformers/model_doc/xglm\"},{\"title\":\"XLM\",\"id\":\"model_doc/xlm\",\"url\":\"/docs/transformers/model_doc/xlm\"},{\"title\":\"XLM-RoBERTa\",\"id\":\"model_doc/xlm-roberta\",\"url\":\"/docs/transformers/model_doc/xlm-roberta\"},{\"title\":\"XLM-RoBERTa-XL\",\"id\":\"model_doc/xlm-roberta-xl\",\"url\":\"/docs/transformers/model_doc/xlm-roberta-xl\"},{\"title\":\"XLM-V\",\"id\":\"model_doc/xlm-v\",\"url\":\"/docs/transformers/model_doc/xlm-v\"},{\"title\":\"XLNet\",\"id\":\"model_doc/xlnet\",\"url\":\"/docs/transformers/model_doc/xlnet\"},{\"title\":\"xLSTM\",\"id\":\"model_doc/xlstm\",\"url\":\"/docs/transformers/model_doc/xlstm\"},{\"title\":\"YOSO\",\"id\":\"model_doc/yoso\",\"url\":\"/docs/transformers/model_doc/yoso\"},{\"title\":\"Zamba\",\"id\":\"model_doc/zamba\",\"url\":\"/docs/transformers/model_doc/zamba\"},{\"title\":\"Zamba2\",\"id\":\"model_doc/zamba2\",\"url\":\"/docs/transformers/model_doc/zamba2\"}]},{\"title\":\"Vision models\",\"isExpanded\":false,\"sections\":[{\"title\":\"Aimv2\",\"id\":\"model_doc/aimv2\",\"url\":\"/docs/transformers/model_doc/aimv2\"},{\"title\":\"BEiT\",\"id\":\"model_doc/beit\",\"url\":\"/docs/transformers/model_doc/beit\"},{\"title\":\"BiT\",\"id\":\"model_doc/bit\",\"url\":\"/docs/transformers/model_doc/bit\"},{\"title\":\"Conditional DETR\",\"id\":\"model_doc/conditional_detr\",\"url\":\"/docs/transformers/model_doc/conditional_detr\"},{\"title\":\"ConvNeXT\",\"id\":\"model_doc/convnext\",\"url\":\"/docs/transformers/model_doc/convnext\"},{\"title\":\"ConvNeXTV2\",\"id\":\"model_doc/convnextv2\",\"url\":\"/docs/transformers/model_doc/convnextv2\"},{\"title\":\"CvT\",\"id\":\"model_doc/cvt\",\"url\":\"/docs/transformers/model_doc/cvt\"},{\"title\":\"D-FINE\",\"id\":\"model_doc/d_fine\",\"url\":\"/docs/transformers/model_doc/d_fine\"},{\"title\":\"DAB-DETR\",\"id\":\"model_doc/dab-detr\",\"url\":\"/docs/transformers/model_doc/dab-detr\"},{\"title\":\"Deformable DETR\",\"id\":\"model_doc/deformable_detr\",\"url\":\"/docs/transformers/model_doc/deformable_detr\"},{\"title\":\"DeiT\",\"id\":\"model_doc/deit\",\"url\":\"/docs/transformers/model_doc/deit\"},{\"title\":\"Depth Anything\",\"id\":\"model_doc/depth_anything\",\"url\":\"/docs/transformers/model_doc/depth_anything\"},{\"title\":\"Depth Anything V2\",\"id\":\"model_doc/depth_anything_v2\",\"url\":\"/docs/transformers/model_doc/depth_anything_v2\"},{\"title\":\"DepthPro\",\"id\":\"model_doc/depth_pro\",\"url\":\"/docs/transformers/model_doc/depth_pro\"},{\"title\":\"DETR\",\"id\":\"model_doc/detr\",\"url\":\"/docs/transformers/model_doc/detr\"},{\"title\":\"DiNAT\",\"id\":\"model_doc/dinat\",\"url\":\"/docs/transformers/model_doc/dinat\"},{\"title\":\"DINOV2\",\"id\":\"model_doc/dinov2\",\"url\":\"/docs/transformers/model_doc/dinov2\"},{\"title\":\"DINOv2 with Registers\",\"id\":\"model_doc/dinov2_with_registers\",\"url\":\"/docs/transformers/model_doc/dinov2_with_registers\"},{\"title\":\"DINOv3\",\"id\":\"model_doc/dinov3\",\"url\":\"/docs/transformers/model_doc/dinov3\"},{\"title\":\"DiT\",\"id\":\"model_doc/dit\",\"url\":\"/docs/transformers/model_doc/dit\"},{\"title\":\"DPT\",\"id\":\"model_doc/dpt\",\"url\":\"/docs/transformers/model_doc/dpt\"},{\"title\":\"EfficientLoFTR\",\"id\":\"model_doc/efficientloftr\",\"url\":\"/docs/transformers/model_doc/efficientloftr\"},{\"title\":\"EfficientNet\",\"id\":\"model_doc/efficientnet\",\"url\":\"/docs/transformers/model_doc/efficientnet\"},{\"title\":\"EoMT\",\"id\":\"model_doc/eomt\",\"url\":\"/docs/transformers/model_doc/eomt\"},{\"title\":\"FocalNet\",\"id\":\"model_doc/focalnet\",\"url\":\"/docs/transformers/model_doc/focalnet\"},{\"title\":\"GLPN\",\"id\":\"model_doc/glpn\",\"url\":\"/docs/transformers/model_doc/glpn\"},{\"title\":\"HGNet-V2\",\"id\":\"model_doc/hgnet_v2\",\"url\":\"/docs/transformers/model_doc/hgnet_v2\"},{\"title\":\"Hiera\",\"id\":\"model_doc/hiera\",\"url\":\"/docs/transformers/model_doc/hiera\"},{\"title\":\"I-JEPA\",\"id\":\"model_doc/ijepa\",\"url\":\"/docs/transformers/model_doc/ijepa\"},{\"title\":\"ImageGPT\",\"id\":\"model_doc/imagegpt\",\"url\":\"/docs/transformers/model_doc/imagegpt\"},{\"title\":\"LeViT\",\"id\":\"model_doc/levit\",\"url\":\"/docs/transformers/model_doc/levit\"},{\"title\":\"LightGlue\",\"id\":\"model_doc/lightglue\",\"url\":\"/docs/transformers/model_doc/lightglue\"},{\"title\":\"Mask2Former\",\"id\":\"model_doc/mask2former\",\"url\":\"/docs/transformers/model_doc/mask2former\"},{\"title\":\"MaskFormer\",\"id\":\"model_doc/maskformer\",\"url\":\"/docs/transformers/model_doc/maskformer\"},{\"title\":\"MLCD\",\"id\":\"model_doc/mlcd\",\"url\":\"/docs/transformers/model_doc/mlcd\"},{\"title\":\"MobileNetV1\",\"id\":\"model_doc/mobilenet_v1\",\"url\":\"/docs/transformers/model_doc/mobilenet_v1\"},{\"title\":\"MobileNetV2\",\"id\":\"model_doc/mobilenet_v2\",\"url\":\"/docs/transformers/model_doc/mobilenet_v2\"},{\"title\":\"MobileViT\",\"id\":\"model_doc/mobilevit\",\"url\":\"/docs/transformers/model_doc/mobilevit\"},{\"title\":\"MobileViTV2\",\"id\":\"model_doc/mobilevitv2\",\"url\":\"/docs/transformers/model_doc/mobilevitv2\"},{\"title\":\"PoolFormer\",\"id\":\"model_doc/poolformer\",\"url\":\"/docs/transformers/model_doc/poolformer\"},{\"title\":\"Prompt Depth Anything\",\"id\":\"model_doc/prompt_depth_anything\",\"url\":\"/docs/transformers/model_doc/prompt_depth_anything\"},{\"title\":\"Pyramid Vision Transformer (PVT)\",\"id\":\"model_doc/pvt\",\"url\":\"/docs/transformers/model_doc/pvt\"},{\"title\":\"Pyramid Vision Transformer v2 (PVTv2)\",\"id\":\"model_doc/pvt_v2\",\"url\":\"/docs/transformers/model_doc/pvt_v2\"},{\"title\":\"RegNet\",\"id\":\"model_doc/regnet\",\"url\":\"/docs/transformers/model_doc/regnet\"},{\"title\":\"ResNet\",\"id\":\"model_doc/resnet\",\"url\":\"/docs/transformers/model_doc/resnet\"},{\"title\":\"RT-DETR\",\"id\":\"model_doc/rt_detr\",\"url\":\"/docs/transformers/model_doc/rt_detr\"},{\"title\":\"RT-DETRv2\",\"id\":\"model_doc/rt_detr_v2\",\"url\":\"/docs/transformers/model_doc/rt_detr_v2\"},{\"title\":\"SAM2\",\"id\":\"model_doc/sam2\",\"url\":\"/docs/transformers/model_doc/sam2\"},{\"title\":\"Sam3Tracker\",\"id\":\"model_doc/sam3_tracker\",\"url\":\"/docs/transformers/model_doc/sam3_tracker\"},{\"title\":\"SegFormer\",\"id\":\"model_doc/segformer\",\"url\":\"/docs/transformers/model_doc/segformer\"},{\"title\":\"SegGpt\",\"id\":\"model_doc/seggpt\",\"url\":\"/docs/transformers/model_doc/seggpt\"},{\"title\":\"Segment Anything\",\"id\":\"model_doc/sam\",\"url\":\"/docs/transformers/model_doc/sam\"},{\"title\":\"Segment Anything High Quality\",\"id\":\"model_doc/sam_hq\",\"url\":\"/docs/transformers/model_doc/sam_hq\"},{\"title\":\"SuperGlue\",\"id\":\"model_doc/superglue\",\"url\":\"/docs/transformers/model_doc/superglue\"},{\"title\":\"SuperPoint\",\"id\":\"model_doc/superpoint\",\"url\":\"/docs/transformers/model_doc/superpoint\"},{\"title\":\"SwiftFormer\",\"id\":\"model_doc/swiftformer\",\"url\":\"/docs/transformers/model_doc/swiftformer\"},{\"title\":\"Swin Transformer\",\"id\":\"model_doc/swin\",\"url\":\"/docs/transformers/model_doc/swin\"},{\"title\":\"Swin Transformer V2\",\"id\":\"model_doc/swinv2\",\"url\":\"/docs/transformers/model_doc/swinv2\"},{\"title\":\"Swin2SR\",\"id\":\"model_doc/swin2sr\",\"url\":\"/docs/transformers/model_doc/swin2sr\"},{\"title\":\"Table Transformer\",\"id\":\"model_doc/table-transformer\",\"url\":\"/docs/transformers/model_doc/table-transformer\"},{\"title\":\"TextNet\",\"id\":\"model_doc/textnet\",\"url\":\"/docs/transformers/model_doc/textnet\"},{\"title\":\"Timm Wrapper\",\"id\":\"model_doc/timm_wrapper\",\"url\":\"/docs/transformers/model_doc/timm_wrapper\"},{\"title\":\"UperNet\",\"id\":\"model_doc/upernet\",\"url\":\"/docs/transformers/model_doc/upernet\"},{\"title\":\"Vision Transformer (ViT)\",\"id\":\"model_doc/vit\",\"url\":\"/docs/transformers/model_doc/vit\"},{\"title\":\"ViTDet\",\"id\":\"model_doc/vitdet\",\"url\":\"/docs/transformers/model_doc/vitdet\"},{\"title\":\"ViTMAE\",\"id\":\"model_doc/vit_mae\",\"url\":\"/docs/transformers/model_doc/vit_mae\"},{\"title\":\"ViTMatte\",\"id\":\"model_doc/vitmatte\",\"url\":\"/docs/transformers/model_doc/vitmatte\"},{\"title\":\"ViTMSN\",\"id\":\"model_doc/vit_msn\",\"url\":\"/docs/transformers/model_doc/vit_msn\"},{\"title\":\"ViTPose\",\"id\":\"model_doc/vitpose\",\"url\":\"/docs/transformers/model_doc/vitpose\"},{\"title\":\"YOLOS\",\"id\":\"model_doc/yolos\",\"url\":\"/docs/transformers/model_doc/yolos\"},{\"title\":\"ZoeDepth\",\"id\":\"model_doc/zoedepth\",\"url\":\"/docs/transformers/model_doc/zoedepth\"}]},{\"title\":\"Audio models\",\"isExpanded\":false,\"sections\":[{\"title\":\"Audio Spectrogram Transformer\",\"id\":\"model_doc/audio-spectrogram-transformer\",\"url\":\"/docs/transformers/model_doc/audio-spectrogram-transformer\"},{\"title\":\"Bark\",\"id\":\"model_doc/bark\",\"url\":\"/docs/transformers/model_doc/bark\"},{\"title\":\"CLAP\",\"id\":\"model_doc/clap\",\"url\":\"/docs/transformers/model_doc/clap\"},{\"title\":\"CSM\",\"id\":\"model_doc/csm\",\"url\":\"/docs/transformers/model_doc/csm\"},{\"title\":\"dac\",\"id\":\"model_doc/dac\",\"url\":\"/docs/transformers/model_doc/dac\"},{\"title\":\"Dia\",\"id\":\"model_doc/dia\",\"url\":\"/docs/transformers/model_doc/dia\"},{\"title\":\"EnCodec\",\"id\":\"model_doc/encodec\",\"url\":\"/docs/transformers/model_doc/encodec\"},{\"title\":\"FastSpeech2Conformer\",\"id\":\"model_doc/fastspeech2_conformer\",\"url\":\"/docs/transformers/model_doc/fastspeech2_conformer\"},{\"title\":\"GraniteSpeech\",\"id\":\"model_doc/granite_speech\",\"url\":\"/docs/transformers/model_doc/granite_speech\"},{\"title\":\"Hubert\",\"id\":\"model_doc/hubert\",\"url\":\"/docs/transformers/model_doc/hubert\"},{\"title\":\"Kyutai Speech-To-Text\",\"id\":\"model_doc/kyutai_speech_to_text\",\"url\":\"/docs/transformers/model_doc/kyutai_speech_to_text\"},{\"title\":\"LASR\",\"id\":\"model_doc/lasr\",\"url\":\"/docs/transformers/model_doc/lasr\"},{\"title\":\"Mimi\",\"id\":\"model_doc/mimi\",\"url\":\"/docs/transformers/model_doc/mimi\"},{\"title\":\"MMS\",\"id\":\"model_doc/mms\",\"url\":\"/docs/transformers/model_doc/mms\"},{\"title\":\"Moonshine\",\"id\":\"model_doc/moonshine\",\"url\":\"/docs/transformers/model_doc/moonshine\"},{\"title\":\"Moshi\",\"id\":\"model_doc/moshi\",\"url\":\"/docs/transformers/model_doc/moshi\"},{\"title\":\"MusicGen\",\"id\":\"model_doc/musicgen\",\"url\":\"/docs/transformers/model_doc/musicgen\"},{\"title\":\"MusicGen Melody\",\"id\":\"model_doc/musicgen_melody\",\"url\":\"/docs/transformers/model_doc/musicgen_melody\"},{\"title\":\"Parakeet\",\"id\":\"model_doc/parakeet\",\"url\":\"/docs/transformers/model_doc/parakeet\"},{\"title\":\"Pop2Piano\",\"id\":\"model_doc/pop2piano\",\"url\":\"/docs/transformers/model_doc/pop2piano\"},{\"title\":\"Seamless-M4T\",\"id\":\"model_doc/seamless_m4t\",\"url\":\"/docs/transformers/model_doc/seamless_m4t\"},{\"title\":\"SeamlessM4T-v2\",\"id\":\"model_doc/seamless_m4t_v2\",\"url\":\"/docs/transformers/model_doc/seamless_m4t_v2\"},{\"title\":\"SEW\",\"id\":\"model_doc/sew\",\"url\":\"/docs/transformers/model_doc/sew\"},{\"title\":\"SEW-D\",\"id\":\"model_doc/sew-d\",\"url\":\"/docs/transformers/model_doc/sew-d\"},{\"title\":\"Speech2Text\",\"id\":\"model_doc/speech_to_text\",\"url\":\"/docs/transformers/model_doc/speech_to_text\"},{\"title\":\"SpeechT5\",\"id\":\"model_doc/speecht5\",\"url\":\"/docs/transformers/model_doc/speecht5\"},{\"title\":\"UniSpeech\",\"id\":\"model_doc/unispeech\",\"url\":\"/docs/transformers/model_doc/unispeech\"},{\"title\":\"UniSpeech-SAT\",\"id\":\"model_doc/unispeech-sat\",\"url\":\"/docs/transformers/model_doc/unispeech-sat\"},{\"title\":\"UnivNet\",\"id\":\"model_doc/univnet\",\"url\":\"/docs/transformers/model_doc/univnet\"},{\"title\":\"VITS\",\"id\":\"model_doc/vits\",\"url\":\"/docs/transformers/model_doc/vits\"},{\"title\":\"Wav2Vec2\",\"id\":\"model_doc/wav2vec2\",\"url\":\"/docs/transformers/model_doc/wav2vec2\"},{\"title\":\"Wav2Vec2-BERT\",\"id\":\"model_doc/wav2vec2-bert\",\"url\":\"/docs/transformers/model_doc/wav2vec2-bert\"},{\"title\":\"Wav2Vec2-Conformer\",\"id\":\"model_doc/wav2vec2-conformer\",\"url\":\"/docs/transformers/model_doc/wav2vec2-conformer\"},{\"title\":\"Wav2Vec2Phoneme\",\"id\":\"model_doc/wav2vec2_phoneme\",\"url\":\"/docs/transformers/model_doc/wav2vec2_phoneme\"},{\"title\":\"WavLM\",\"id\":\"model_doc/wavlm\",\"url\":\"/docs/transformers/model_doc/wavlm\"},{\"title\":\"Whisper\",\"id\":\"model_doc/whisper\",\"url\":\"/docs/transformers/model_doc/whisper\"},{\"title\":\"X-Codec\",\"id\":\"model_doc/xcodec\",\"url\":\"/docs/transformers/model_doc/xcodec\"},{\"title\":\"XLS-R\",\"id\":\"model_doc/xls_r\",\"url\":\"/docs/transformers/model_doc/xls_r\"},{\"title\":\"XLSR-Wav2Vec2\",\"id\":\"model_doc/xlsr_wav2vec2\",\"url\":\"/docs/transformers/model_doc/xlsr_wav2vec2\"}]},{\"title\":\"Video models\",\"isExpanded\":false,\"sections\":[{\"title\":\"SAM2 Video\",\"id\":\"model_doc/sam2_video\",\"url\":\"/docs/transformers/model_doc/sam2_video\"},{\"title\":\"Sam3TrackerVideo\",\"id\":\"model_doc/sam3_tracker_video\",\"url\":\"/docs/transformers/model_doc/sam3_tracker_video\"},{\"title\":\"TimeSformer\",\"id\":\"model_doc/timesformer\",\"url\":\"/docs/transformers/model_doc/timesformer\"},{\"title\":\"V-JEPA 2\",\"id\":\"model_doc/vjepa2\",\"url\":\"/docs/transformers/model_doc/vjepa2\"},{\"title\":\"VideoMAE\",\"id\":\"model_doc/videomae\",\"url\":\"/docs/transformers/model_doc/videomae\"},{\"title\":\"ViViT\",\"id\":\"model_doc/vivit\",\"url\":\"/docs/transformers/model_doc/vivit\"}]},{\"title\":\"Multimodal models\",\"isExpanded\":false,\"sections\":[{\"title\":\"ALIGN\",\"id\":\"model_doc/align\",\"url\":\"/docs/transformers/model_doc/align\"},{\"title\":\"AltCLIP\",\"id\":\"model_doc/altclip\",\"url\":\"/docs/transformers/model_doc/altclip\"},{\"title\":\"Aria\",\"id\":\"model_doc/aria\",\"url\":\"/docs/transformers/model_doc/aria\"},{\"title\":\"AudioFlamingo3\",\"id\":\"model_doc/audioflamingo3\",\"url\":\"/docs/transformers/model_doc/audioflamingo3\"},{\"title\":\"AyaVision\",\"id\":\"model_doc/aya_vision\",\"url\":\"/docs/transformers/model_doc/aya_vision\"},{\"title\":\"BLIP\",\"id\":\"model_doc/blip\",\"url\":\"/docs/transformers/model_doc/blip\"},{\"title\":\"BLIP-2\",\"id\":\"model_doc/blip-2\",\"url\":\"/docs/transformers/model_doc/blip-2\"},{\"title\":\"BridgeTower\",\"id\":\"model_doc/bridgetower\",\"url\":\"/docs/transformers/model_doc/bridgetower\"},{\"title\":\"BROS\",\"id\":\"model_doc/bros\",\"url\":\"/docs/transformers/model_doc/bros\"},{\"title\":\"Chameleon\",\"id\":\"model_doc/chameleon\",\"url\":\"/docs/transformers/model_doc/chameleon\"},{\"title\":\"Chinese-CLIP\",\"id\":\"model_doc/chinese_clip\",\"url\":\"/docs/transformers/model_doc/chinese_clip\"},{\"title\":\"CLIP\",\"id\":\"model_doc/clip\",\"url\":\"/docs/transformers/model_doc/clip\"},{\"title\":\"CLIPSeg\",\"id\":\"model_doc/clipseg\",\"url\":\"/docs/transformers/model_doc/clipseg\"},{\"title\":\"CLVP\",\"id\":\"model_doc/clvp\",\"url\":\"/docs/transformers/model_doc/clvp\"},{\"title\":\"Code World Model (CWM)\",\"id\":\"model_doc/cwm\",\"url\":\"/docs/transformers/model_doc/cwm\"},{\"title\":\"Cohere2Vision\",\"id\":\"model_doc/cohere2_vision\",\"url\":\"/docs/transformers/model_doc/cohere2_vision\"},{\"title\":\"ColPali\",\"id\":\"model_doc/colpali\",\"url\":\"/docs/transformers/model_doc/colpali\"},{\"title\":\"ColQwen2\",\"id\":\"model_doc/colqwen2\",\"url\":\"/docs/transformers/model_doc/colqwen2\"},{\"title\":\"Data2Vec\",\"id\":\"model_doc/data2vec\",\"url\":\"/docs/transformers/model_doc/data2vec\"},{\"title\":\"DeepseekVL\",\"id\":\"model_doc/deepseek_vl\",\"url\":\"/docs/transformers/model_doc/deepseek_vl\"},{\"title\":\"DeepseekVLHybrid\",\"id\":\"model_doc/deepseek_vl_hybrid\",\"url\":\"/docs/transformers/model_doc/deepseek_vl_hybrid\"},{\"title\":\"DePlot\",\"id\":\"model_doc/deplot\",\"url\":\"/docs/transformers/model_doc/deplot\"},{\"title\":\"Donut\",\"id\":\"model_doc/donut\",\"url\":\"/docs/transformers/model_doc/donut\"},{\"title\":\"EdgeTAM\",\"id\":\"model_doc/edgetam\",\"url\":\"/docs/transformers/model_doc/edgetam\"},{\"title\":\"EdgeTamVideo\",\"id\":\"model_doc/edgetam_video\",\"url\":\"/docs/transformers/model_doc/edgetam_video\"},{\"title\":\"Emu3\",\"id\":\"model_doc/emu3\",\"url\":\"/docs/transformers/model_doc/emu3\"},{\"title\":\"Evolla\",\"id\":\"model_doc/evolla\",\"url\":\"/docs/transformers/model_doc/evolla\"},{\"title\":\"FastVLM\",\"id\":\"model_doc/fast_vlm\",\"url\":\"/docs/transformers/model_doc/fast_vlm\"},{\"title\":\"FLAVA\",\"id\":\"model_doc/flava\",\"url\":\"/docs/transformers/model_doc/flava\"},{\"title\":\"Florence2\",\"id\":\"model_doc/florence2\",\"url\":\"/docs/transformers/model_doc/florence2\"},{\"title\":\"Gemma3\",\"id\":\"model_doc/gemma3\",\"url\":\"/docs/transformers/model_doc/gemma3\"},{\"title\":\"Gemma3n\",\"id\":\"model_doc/gemma3n\",\"url\":\"/docs/transformers/model_doc/gemma3n\"},{\"title\":\"GIT\",\"id\":\"model_doc/git\",\"url\":\"/docs/transformers/model_doc/git\"},{\"title\":\"Glm46V\",\"id\":\"model_doc/glm46v\",\"url\":\"/docs/transformers/model_doc/glm46v\"},{\"title\":\"glm4v\",\"id\":\"model_doc/glm4v\",\"url\":\"/docs/transformers/model_doc/glm4v\"},{\"title\":\"glm4v_moe\",\"id\":\"model_doc/glm4v_moe\",\"url\":\"/docs/transformers/model_doc/glm4v_moe\"},{\"title\":\"GOT-OCR2\",\"id\":\"model_doc/got_ocr2\",\"url\":\"/docs/transformers/model_doc/got_ocr2\"},{\"title\":\"GraniteVision\",\"id\":\"model_doc/granitevision\",\"url\":\"/docs/transformers/model_doc/granitevision\"},{\"title\":\"Grounding DINO\",\"id\":\"model_doc/grounding-dino\",\"url\":\"/docs/transformers/model_doc/grounding-dino\"},{\"title\":\"GroupViT\",\"id\":\"model_doc/groupvit\",\"url\":\"/docs/transformers/model_doc/groupvit\"},{\"title\":\"IDEFICS\",\"id\":\"model_doc/idefics\",\"url\":\"/docs/transformers/model_doc/idefics\"},{\"title\":\"Idefics2\",\"id\":\"model_doc/idefics2\",\"url\":\"/docs/transformers/model_doc/idefics2\"},{\"title\":\"Idefics3\",\"id\":\"model_doc/idefics3\",\"url\":\"/docs/transformers/model_doc/idefics3\"},{\"title\":\"InstructBLIP\",\"id\":\"model_doc/instructblip\",\"url\":\"/docs/transformers/model_doc/instructblip\"},{\"title\":\"InstructBlipVideo\",\"id\":\"model_doc/instructblipvideo\",\"url\":\"/docs/transformers/model_doc/instructblipvideo\"},{\"title\":\"InternVL\",\"id\":\"model_doc/internvl\",\"url\":\"/docs/transformers/model_doc/internvl\"},{\"title\":\"Janus\",\"id\":\"model_doc/janus\",\"url\":\"/docs/transformers/model_doc/janus\"},{\"title\":\"KOSMOS-2\",\"id\":\"model_doc/kosmos-2\",\"url\":\"/docs/transformers/model_doc/kosmos-2\"},{\"title\":\"KOSMOS-2.5\",\"id\":\"model_doc/kosmos2_5\",\"url\":\"/docs/transformers/model_doc/kosmos2_5\"},{\"title\":\"LayoutLM\",\"id\":\"model_doc/layoutlm\",\"url\":\"/docs/transformers/model_doc/layoutlm\"},{\"title\":\"LayoutLMV2\",\"id\":\"model_doc/layoutlmv2\",\"url\":\"/docs/transformers/model_doc/layoutlmv2\"},{\"title\":\"LayoutLMV3\",\"id\":\"model_doc/layoutlmv3\",\"url\":\"/docs/transformers/model_doc/layoutlmv3\"},{\"title\":\"LayoutXLM\",\"id\":\"model_doc/layoutxlm\",\"url\":\"/docs/transformers/model_doc/layoutxlm\"},{\"title\":\"LFM2-VL\",\"id\":\"model_doc/lfm2_vl\",\"url\":\"/docs/transformers/model_doc/lfm2_vl\"},{\"title\":\"LiLT\",\"id\":\"model_doc/lilt\",\"url\":\"/docs/transformers/model_doc/lilt\"},{\"title\":\"Llama4\",\"id\":\"model_doc/llama4\",\"url\":\"/docs/transformers/model_doc/llama4\"},{\"title\":\"LLaVA\",\"id\":\"model_doc/llava\",\"url\":\"/docs/transformers/model_doc/llava\"},{\"title\":\"LLaVA-NeXT\",\"id\":\"model_doc/llava_next\",\"url\":\"/docs/transformers/model_doc/llava_next\"},{\"title\":\"LLaVa-NeXT-Video\",\"id\":\"model_doc/llava_next_video\",\"url\":\"/docs/transformers/model_doc/llava_next_video\"},{\"title\":\"LLaVA-Onevision\",\"id\":\"model_doc/llava_onevision\",\"url\":\"/docs/transformers/model_doc/llava_onevision\"},{\"title\":\"LXMERT\",\"id\":\"model_doc/lxmert\",\"url\":\"/docs/transformers/model_doc/lxmert\"},{\"title\":\"MatCha\",\"id\":\"model_doc/matcha\",\"url\":\"/docs/transformers/model_doc/matcha\"},{\"title\":\"MetaCLIP 2\",\"id\":\"model_doc/metaclip_2\",\"url\":\"/docs/transformers/model_doc/metaclip_2\"},{\"title\":\"MGP-STR\",\"id\":\"model_doc/mgp-str\",\"url\":\"/docs/transformers/model_doc/mgp-str\"},{\"title\":\"Mistral3\",\"id\":\"model_doc/mistral3\",\"url\":\"/docs/transformers/model_doc/mistral3\"},{\"title\":\"mllama\",\"id\":\"model_doc/mllama\",\"url\":\"/docs/transformers/model_doc/mllama\"},{\"title\":\"MM Grounding DINO\",\"id\":\"model_doc/mm-grounding-dino\",\"url\":\"/docs/transformers/model_doc/mm-grounding-dino\"},{\"title\":\"Nougat\",\"id\":\"model_doc/nougat\",\"url\":\"/docs/transformers/model_doc/nougat\"},{\"title\":\"OmDet-Turbo\",\"id\":\"model_doc/omdet-turbo\",\"url\":\"/docs/transformers/model_doc/omdet-turbo\"},{\"title\":\"OneFormer\",\"id\":\"model_doc/oneformer\",\"url\":\"/docs/transformers/model_doc/oneformer\"},{\"title\":\"Ovis2\",\"id\":\"model_doc/ovis2\",\"url\":\"/docs/transformers/model_doc/ovis2\"},{\"title\":\"OWL-ViT\",\"id\":\"model_doc/owlvit\",\"url\":\"/docs/transformers/model_doc/owlvit\"},{\"title\":\"OWLv2\",\"id\":\"model_doc/owlv2\",\"url\":\"/docs/transformers/model_doc/owlv2\"},{\"title\":\"PaddleOCRVL\",\"id\":\"model_doc/paddleocr_vl\",\"url\":\"/docs/transformers/model_doc/paddleocr_vl\"},{\"title\":\"PaliGemma\",\"id\":\"model_doc/paligemma\",\"url\":\"/docs/transformers/model_doc/paligemma\"},{\"title\":\"Perceiver\",\"id\":\"model_doc/perceiver\",\"url\":\"/docs/transformers/model_doc/perceiver\"},{\"title\":\"PerceptionLM\",\"id\":\"model_doc/perception_lm\",\"url\":\"/docs/transformers/model_doc/perception_lm\"},{\"title\":\"Phi4 Multimodal\",\"id\":\"model_doc/phi4_multimodal\",\"url\":\"/docs/transformers/model_doc/phi4_multimodal\"},{\"title\":\"Pix2Struct\",\"id\":\"model_doc/pix2struct\",\"url\":\"/docs/transformers/model_doc/pix2struct\"},{\"title\":\"Pixtral\",\"id\":\"model_doc/pixtral\",\"url\":\"/docs/transformers/model_doc/pixtral\"},{\"title\":\"Qwen2.5-Omni\",\"id\":\"model_doc/qwen2_5_omni\",\"url\":\"/docs/transformers/model_doc/qwen2_5_omni\"},{\"title\":\"Qwen2.5-VL\",\"id\":\"model_doc/qwen2_5_vl\",\"url\":\"/docs/transformers/model_doc/qwen2_5_vl\"},{\"title\":\"Qwen2Audio\",\"id\":\"model_doc/qwen2_audio\",\"url\":\"/docs/transformers/model_doc/qwen2_audio\"},{\"title\":\"Qwen2VL\",\"id\":\"model_doc/qwen2_vl\",\"url\":\"/docs/transformers/model_doc/qwen2_vl\"},{\"title\":\"Qwen3-Omni-MoE\",\"id\":\"model_doc/qwen3_omni_moe\",\"url\":\"/docs/transformers/model_doc/qwen3_omni_moe\"},{\"title\":\"Qwen3VL\",\"id\":\"model_doc/qwen3_vl\",\"url\":\"/docs/transformers/model_doc/qwen3_vl\"},{\"title\":\"Qwen3VLMoe\",\"id\":\"model_doc/qwen3_vl_moe\",\"url\":\"/docs/transformers/model_doc/qwen3_vl_moe\"},{\"title\":\"SAM3\",\"id\":\"model_doc/sam3\",\"url\":\"/docs/transformers/model_doc/sam3\"},{\"title\":\"SAM3 Video\",\"id\":\"model_doc/sam3_video\",\"url\":\"/docs/transformers/model_doc/sam3_video\"},{\"title\":\"ShieldGemma2\",\"id\":\"model_doc/shieldgemma2\",\"url\":\"/docs/transformers/model_doc/shieldgemma2\"},{\"title\":\"SigLIP\",\"id\":\"model_doc/siglip\",\"url\":\"/docs/transformers/model_doc/siglip\"},{\"title\":\"SigLIP2\",\"id\":\"model_doc/siglip2\",\"url\":\"/docs/transformers/model_doc/siglip2\"},{\"title\":\"SmolLM3\",\"id\":\"model_doc/smollm3\",\"url\":\"/docs/transformers/model_doc/smollm3\"},{\"title\":\"SmolVLM\",\"id\":\"model_doc/smolvlm\",\"url\":\"/docs/transformers/model_doc/smolvlm\"},{\"title\":\"Speech Encoder Decoder Models\",\"id\":\"model_doc/speech-encoder-decoder\",\"url\":\"/docs/transformers/model_doc/speech-encoder-decoder\"},{\"title\":\"TAPAS\",\"id\":\"model_doc/tapas\",\"url\":\"/docs/transformers/model_doc/tapas\"},{\"title\":\"TrOCR\",\"id\":\"model_doc/trocr\",\"url\":\"/docs/transformers/model_doc/trocr\"},{\"title\":\"TVP\",\"id\":\"model_doc/tvp\",\"url\":\"/docs/transformers/model_doc/tvp\"},{\"title\":\"UDOP\",\"id\":\"model_doc/udop\",\"url\":\"/docs/transformers/model_doc/udop\"},{\"title\":\"VideoLlama3\",\"id\":\"model_doc/video_llama_3\",\"url\":\"/docs/transformers/model_doc/video_llama_3\"},{\"title\":\"VideoLlava\",\"id\":\"model_doc/video_llava\",\"url\":\"/docs/transformers/model_doc/video_llava\"},{\"title\":\"ViLT\",\"id\":\"model_doc/vilt\",\"url\":\"/docs/transformers/model_doc/vilt\"},{\"title\":\"VipLlava\",\"id\":\"model_doc/vipllava\",\"url\":\"/docs/transformers/model_doc/vipllava\"},{\"title\":\"Vision Encoder Decoder Models\",\"id\":\"model_doc/vision-encoder-decoder\",\"url\":\"/docs/transformers/model_doc/vision-encoder-decoder\"},{\"title\":\"Vision Text Dual Encoder\",\"id\":\"model_doc/vision-text-dual-encoder\",\"url\":\"/docs/transformers/model_doc/vision-text-dual-encoder\"},{\"title\":\"VisualBERT\",\"id\":\"model_doc/visual_bert\",\"url\":\"/docs/transformers/model_doc/visual_bert\"},{\"title\":\"Voxtral\",\"id\":\"model_doc/voxtral\",\"url\":\"/docs/transformers/model_doc/voxtral\"},{\"title\":\"X-CLIP\",\"id\":\"model_doc/xclip\",\"url\":\"/docs/transformers/model_doc/xclip\"}]},{\"title\":\"Reinforcement learning models\",\"isExpanded\":false,\"sections\":[{\"title\":\"Decision Transformer\",\"id\":\"model_doc/decision_transformer\",\"url\":\"/docs/transformers/model_doc/decision_transformer\"}]},{\"title\":\"Time series models\",\"isExpanded\":false,\"sections\":[{\"title\":\"Autoformer\",\"id\":\"model_doc/autoformer\",\"url\":\"/docs/transformers/model_doc/autoformer\"},{\"title\":\"Informer\",\"id\":\"model_doc/informer\",\"url\":\"/docs/transformers/model_doc/informer\"},{\"title\":\"PatchTSMixer\",\"id\":\"model_doc/patchtsmixer\",\"url\":\"/docs/transformers/model_doc/patchtsmixer\"},{\"title\":\"PatchTST\",\"id\":\"model_doc/patchtst\",\"url\":\"/docs/transformers/model_doc/patchtst\"},{\"title\":\"Time Series Transformer\",\"id\":\"model_doc/time_series_transformer\",\"url\":\"/docs/transformers/model_doc/time_series_transformer\"},{\"title\":\"TimesFM\",\"id\":\"model_doc/timesfm\",\"url\":\"/docs/transformers/model_doc/timesfm\"}]}]},{\"title\":\"Internal helpers\",\"isExpanded\":false,\"sections\":[{\"title\":\"Custom Layers and Utilities\",\"id\":\"internal/modeling_utils\",\"url\":\"/docs/transformers/internal/modeling_utils\"},{\"title\":\"Utilities for Model Debugging\",\"id\":\"internal/model_debugging_utils\",\"url\":\"/docs/transformers/internal/model_debugging_utils\"},{\"title\":\"Utilities for pipelines\",\"id\":\"internal/pipelines_utils\",\"url\":\"/docs/transformers/internal/pipelines_utils\"},{\"title\":\"Utilities for Tokenizers\",\"id\":\"internal/tokenization_utils\",\"url\":\"/docs/transformers/internal/tokenization_utils\"},{\"title\":\"Utilities for Trainer\",\"id\":\"internal/trainer_utils\",\"url\":\"/docs/transformers/internal/trainer_utils\"},{\"title\":\"Utilities for Generation\",\"id\":\"internal/generation_utils\",\"url\":\"/docs/transformers/internal/generation_utils\"},{\"title\":\"Utilities for Image Processors\",\"id\":\"internal/image_processing_utils\",\"url\":\"/docs/transformers/internal/image_processing_utils\"},{\"title\":\"Utilities for Audio processing\",\"id\":\"internal/audio_utils\",\"url\":\"/docs/transformers/internal/audio_utils\"},{\"title\":\"General Utilities\",\"id\":\"internal/file_utils\",\"url\":\"/docs/transformers/internal/file_utils\"},{\"title\":\"Importing Utilities\",\"id\":\"internal/import_utils\",\"url\":\"/docs/transformers/internal/import_utils\"},{\"title\":\"Utilities for Time Series\",\"id\":\"internal/time_series_utils\",\"url\":\"/docs/transformers/internal/time_series_utils\"},{\"title\":\"Rotary Embeddings Utilities\",\"id\":\"internal/rope_utils\",\"url\":\"/docs/transformers/internal/rope_utils\"}]},{\"title\":\"Reference\",\"isExpanded\":false,\"sections\":[{\"title\":\"Environment Variables\",\"id\":\"reference/environment_variables\",\"url\":\"/docs/transformers/reference/environment_variables\"}]}]}],\"chapterId\":\"llm_tutorial\",\"docType\":\"docs\",\"isLoggedIn\":false,\"lang\":\"en\",\"langs\":[\"ar\",\"de\",\"en\",\"es\",\"fr\",\"hi\",\"it\",\"ja\",\"ko\",\"pt\",\"zh\"],\"library\":\"transformers\",\"theme\":\"light\",\"version\":\"v5.0.0rc1\",\"versions\":[{\"version\":\"main\"},{\"version\":\"v5.0.0rc1\"},{\"version\":\"v5.0.0rc0\"},{\"version\":\"v4.57.3\"},{\"version\":\"v4.57.2\"},{\"version\":\"v4.57.1\"},{\"version\":\"v4.57.0\"},{\"version\":\"v4.56.2\"},{\"version\":\"v4.56.1\"},{\"version\":\"v4.56.0\"},{\"version\":\"v4.55.4\"},{\"version\":\"v4.53.3\"},{\"version\":\"v4.53.2\"},{\"version\":\"v4.53.1\"},{\"version\":\"v4.53.0\"},{\"version\":\"v4.52.3\"},{\"version\":\"v4.52.2\"},{\"version\":\"v4.52.1\"},{\"version\":\"v4.51.3\"},{\"version\":\"v4.51.1\"},{\"version\":\"v4.50.0\"},{\"version\":\"v4.49.0\"},{\"version\":\"v4.48.2\"},{\"version\":\"v4.48.1\"},{\"version\":\"v4.48.0\"},{\"version\":\"v4.47.1\"},{\"version\":\"v4.47.0\"},{\"version\":\"v4.46.3\"},{\"version\":\"v4.46.2\"},{\"version\":\"v4.46.0\"},{\"version\":\"v4.45.2\"},{\"version\":\"v4.45.1\"},{\"version\":\"v4.44.2\"},{\"version\":\"v4.44.1\"},{\"version\":\"v4.44.0\"},{\"version\":\"v4.43.4\"},{\"version\":\"v4.43.3\"},{\"version\":\"v4.43.2\"},{\"version\":\"v4.43.0\"},{\"version\":\"v4.42.4\"},{\"version\":\"v4.42.0\"},{\"version\":\"v4.41.2\"},{\"version\":\"v4.41.1\"},{\"version\":\"v4.41.0\"},{\"version\":\"v4.40.2\"},{\"version\":\"v4.40.1\"},{\"version\":\"v4.40.0\"},{\"version\":\"v4.39.3\"},{\"version\":\"v4.39.2\"},{\"version\":\"v4.39.1\"},{\"version\":\"v4.39.0\"},{\"version\":\"v4.38.2\"},{\"version\":\"v4.38.1\"},{\"version\":\"v4.38.0\"},{\"version\":\"v4.37.2\"},{\"version\":\"v4.37.1\"},{\"version\":\"v4.37.0\"},{\"version\":\"v4.36.1\"},{\"version\":\"v4.36.0\"},{\"version\":\"v4.35.2\"},{\"version\":\"v4.35.1\"},{\"version\":\"v4.35.0\"},{\"version\":\"v4.34.1\"},{\"version\":\"v4.34.0\"},{\"version\":\"v4.33.3\"},{\"version\":\"v4.33.2\"},{\"version\":\"v4.33.0\"},{\"version\":\"v4.32.1\"},{\"version\":\"v4.32.0\"},{\"version\":\"v4.31.0\"},{\"version\":\"v4.30.0\"},{\"version\":\"v4.29.1\"},{\"version\":\"v4.29.0\"},{\"version\":\"v4.28.1\"},{\"version\":\"v4.28.0\"},{\"version\":\"v4.27.2\"},{\"version\":\"v4.27.1\"},{\"version\":\"v4.27.0\"},{\"version\":\"v4.26.1\"},{\"version\":\"v4.26.0\"},{\"version\":\"v4.25.1\"},{\"version\":\"v4.24.0\"},{\"version\":\"v4.23.1\"},{\"version\":\"v4.23.0\"},{\"version\":\"v4.22.2\"},{\"version\":\"v4.22.1\"},{\"version\":\"v4.22.0\"},{\"version\":\"v4.21.3\"},{\"version\":\"v4.21.2\"},{\"version\":\"v4.21.1\"},{\"version\":\"v4.21.0\"},{\"version\":\"v4.20.1\"},{\"version\":\"v4.20.0\"},{\"version\":\"v4.19.4\"},{\"version\":\"v4.19.3\"},{\"version\":\"v4.19.2\"},{\"version\":\"v4.19.0\"},{\"version\":\"v4.18.0\"},{\"version\":\"v4.17.0\"},{\"version\":\"v4.16.2\"},{\"version\":\"v4.16.1\"},{\"version\":\"v4.16.0\"},{\"version\":\"v4.15.0\"},{\"version\":\"v4.14.1\"},{\"version\":\"v4.13.0\"},{\"sphinx\":true,\"version\":\"v4.12.5\"},{\"sphinx\":true,\"version\":\"v4.12.4\"},{\"sphinx\":true,\"version\":\"v4.12.2\"},{\"sphinx\":true,\"version\":\"v4.12.1\"},{\"sphinx\":true,\"version\":\"v4.12.0\"},{\"sphinx\":true,\"version\":\"v4.11.3\"},{\"sphinx\":true,\"version\":\"v4.11.2\"},{\"sphinx\":true,\"version\":\"v4.11.1\"},{\"sphinx\":true,\"version\":\"v4.11.0\"},{\"sphinx\":true,\"version\":\"v4.10.1\"},{\"sphinx\":true,\"version\":\"v4.10.0\"},{\"sphinx\":true,\"version\":\"v4.9.2\"},{\"sphinx\":true,\"version\":\"v4.9.1\"},{\"sphinx\":true,\"version\":\"v4.9.0\"},{\"sphinx\":true,\"version\":\"v4.8.2\"},{\"sphinx\":true,\"version\":\"v4.8.1\"},{\"sphinx\":true,\"version\":\"v4.8.0\"},{\"sphinx\":true,\"version\":\"v4.7.0\"},{\"sphinx\":true,\"version\":\"v4.6.0\"},{\"sphinx\":true,\"version\":\"v4.5.1\"},{\"sphinx\":true,\"version\":\"v4.5.0\"},{\"sphinx\":true,\"version\":\"v4.4.2\"},{\"sphinx\":true,\"version\":\"v4.4.1\"},{\"sphinx\":true,\"version\":\"v4.4.0\"},{\"sphinx\":true,\"version\":\"v4.3.3\"},{\"sphinx\":true,\"version\":\"v4.3.2\"},{\"sphinx\":true,\"version\":\"v4.3.1\"},{\"sphinx\":true,\"version\":\"v4.3.0\"},{\"sphinx\":true,\"version\":\"v4.2.2\"},{\"sphinx\":true,\"version\":\"v4.2.1\"},{\"sphinx\":true,\"version\":\"v4.2.0\"},{\"sphinx\":true,\"version\":\"v4.1.1\"},{\"sphinx\":true,\"version\":\"v4.1.0\"},{\"sphinx\":true,\"version\":\"v4.0.1\"},{\"sphinx\":true,\"version\":\"v4.0.0\"},{\"sphinx\":true,\"version\":\"v3.5.1\"},{\"sphinx\":true,\"version\":\"v3.5.0\"},{\"sphinx\":true,\"version\":\"v3.4.0\"},{\"sphinx\":true,\"version\":\"v3.3.1\"},{\"sphinx\":true,\"version\":\"v3.3.0\"},{\"sphinx\":true,\"version\":\"v3.2.0\"},{\"sphinx\":true,\"version\":\"v3.1.0\"},{\"sphinx\":true,\"version\":\"v3.0.2\"},{\"sphinx\":true,\"version\":\"v3.0.1\"},{\"sphinx\":true,\"version\":\"v3.0.0\"},{\"sphinx\":true,\"version\":\"v2.11.0\"},{\"sphinx\":true,\"version\":\"v2.10.0\"},{\"sphinx\":true,\"version\":\"v2.9.1\"},{\"sphinx\":true,\"version\":\"v2.9.0\"},{\"sphinx\":true,\"version\":\"v2.8.0\"},{\"sphinx\":true,\"version\":\"v2.7.0\"},{\"sphinx\":true,\"version\":\"v2.6.0\"},{\"sphinx\":true,\"version\":\"v2.5.1\"},{\"sphinx\":true,\"version\":\"v2.5.0\"},{\"sphinx\":true,\"version\":\"v2.4.1\"},{\"sphinx\":true,\"version\":\"v2.4.0\"},{\"sphinx\":true,\"version\":\"v2.3.0\"},{\"sphinx\":true,\"version\":\"v2.2.2\"},{\"sphinx\":true,\"version\":\"v2.2.1\"},{\"sphinx\":true,\"version\":\"v2.2.0\"},{\"sphinx\":true,\"version\":\"v2.1.1\"},{\"sphinx\":true,\"version\":\"v2.0.0\"},{\"sphinx\":true,\"version\":\"v1.2.0\"},{\"sphinx\":true,\"version\":\"v1.1.0\"},{\"sphinx\":true,\"version\":\"v1.0.0\"},{\"version\":\"doc-builder-html\"}],\"title\":\"Text generation\"}' data-target=\"SideMenu\">\n<dialog class=\"shadow-alternate z-40 mx-4 my-auto h-fit select-text overflow-hidden rounded-xl bg-white max-sm:max-w-[calc(100dvw-2rem)] sm:mx-auto lg:mt-26 md:portrait:mt-30 xl:mt-30 2xl:mt-32 w-full lg:w-7/12 max-w-[calc(100%-4rem)] md:max-w-2xl dark:bg-gray-950 py-3 mt-16! !2xl:mt-24 w-[500px]! max-h-[500px]!\">\n<div class=\"outline-none focus:ring-0 focus-visible:ring-0\" tabindex=\"-1\"></div></dialog>\n<div class=\"z-2 w-full flex-none lg:flex lg:h-dvh lg:w-[270px] lg:flex-col 2xl:w-[300px] false\"><div class=\"shadow-alternate flex h-auto w-full items-center rounded-b-xl border-b bg-white py-2 text-lg leading-tight lg:hidden\">\n<div class=\"flex flex-1 cursor-pointer flex-col justify-center self-stretch pl-6\"><p class=\"text-sm text-gray-400 first-letter:capitalize\">Transformers documentation\n\t\t\t</p>\n<div class=\"mr-2 flex items-center\"><p class=\"font-semibold\">Text generation</p>\n<svg aria-hidden=\"true\" class=\"text-xl false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg></div></div>\n<button class=\"hover:shadow-alternate group ml-auto mr-6 inline-flex flex-none cursor-pointer rounded-xl border p-2\"><svg aria-hidden=\"true\" class=\"text-gray-500 group-hover:text-gray-700\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg></button></div>\n<div class=\"bg-linear-to-r hidden flex-col justify-between border-b border-r bg-white p-4 lg:flex from-orange-50 to-white dark:from-gray-900 dark:to-gray-950\"><div class=\"group relative mb-2 flex min-w-[50%] items-center self-start text-lg font-bold leading-tight first-letter:capitalize\"><div class=\"mr-1.5 h-1.5 w-1.5 rounded-full bg-orange-500 flex-none\"></div>\n<h1>Transformers</h1>\n<svg aria-hidden=\"true\" class=\"opacity-50 ml-0.5 flex-none group-hover:opacity-100\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M16.293 9.293L12 13.586L7.707 9.293l-1.414 1.414L12 16.414l5.707-5.707z\" fill=\"currentColor\"></path></svg>\n<select class=\"outline-hidden absolute inset-0 border-none bg-white text-base opacity-0\"><option value=\"/docs\">ð¡ View all docs</option><option value=\"/docs/optimum-neuron\">AWS Trainium &amp; Inferentia</option><option value=\"/docs/accelerate\">Accelerate</option><option value=\"https://argilla-io.github.io/argilla/\">Argilla</option><option value=\"/docs/autotrain\">AutoTrain</option><option value=\"/docs/bitsandbytes\">Bitsandbytes</option><option value=\"/docs/chat-ui\">Chat UI</option><option value=\"/docs/dataset-viewer\">Dataset viewer</option><option value=\"/docs/datasets\">Datasets</option><option value=\"/docs/sagemaker\">Deploying on AWS</option><option value=\"/docs/diffusers\">Diffusers</option><option value=\"https://distilabel.argilla.io/\">Distilabel</option><option value=\"/docs/evaluate\">Evaluate</option><option value=\"/docs/google-cloud\">Google Cloud</option><option value=\"/docs/optimum-tpu\">Google TPUs</option><option value=\"https://www.gradio.app/docs/\">Gradio</option><option value=\"/docs/hub\">Hub</option><option value=\"/docs/huggingface_hub\">Hub Python Library</option><option value=\"/docs/huggingface.js\">Huggingface.js</option><option value=\"/docs/inference-endpoints\">Inference Endpoints (dedicated)</option><option value=\"/docs/inference-providers\">Inference Providers</option><option value=\"/docs/kernels\">Kernels</option><option value=\"/docs/lerobot\">LeRobot</option><option value=\"/docs/leaderboards\">Leaderboards</option><option value=\"/docs/lighteval\">Lighteval</option><option value=\"/docs/microsoft-azure\">Microsoft Azure</option><option value=\"/docs/optimum\">Optimum</option><option value=\"/docs/peft\">PEFT</option><option value=\"/docs/safetensors\">Safetensors</option><option value=\"https://sbert.net/\">Sentence Transformers</option><option value=\"/docs/trl\">TRL</option><option value=\"/tasks\">Tasks</option><option value=\"/docs/text-embeddings-inference\">Text Embeddings Inference</option><option value=\"/docs/text-generation-inference\">Text Generation Inference</option><option value=\"/docs/tokenizers\">Tokenizers</option><option value=\"/docs/trackio\">Trackio</option><option selected=\"\" value=\"/docs/transformers\">Transformers</option><option value=\"/docs/transformers.js\">Transformers.js</option><option value=\"/docs/smolagents\">smolagents</option><option value=\"/docs/timm\">timm</option></select></div>\n<button class=\"shadow-alternate mb-2 flex w-full items-center rounded-full border bg-white px-2 py-1 text-left text-sm text-gray-400 ring-indigo-200 hover:bg-indigo-50 hover:ring-2 dark:border-gray-700 dark:ring-yellow-600 dark:hover:bg-gray-900 dark:hover:text-yellow-500\"><svg aria-hidden=\"true\" class=\"flex-none mr-1.5\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M30 28.59L22.45 21A11 11 0 1 0 21 22.45L28.59 30zM5 14a9 9 0 1 1 9 9a9 9 0 0 1-9-9z\" fill=\"currentColor\"></path></svg>\n<div>Search documentation</div>\n</button>\n<div class=\"flex items-center\">\n<select class=\"form-input mt-0! w-20! border! dark:text-gray-400! mr-1 rounded-sm border-gray-200 p-1 text-xs uppercase\"><option value=\"0\">main</option><option selected=\"\" value=\"1\">v5.0.0rc1</option><option value=\"2\">v4.57.3</option><option value=\"3\">v4.56.2</option><option value=\"4\">v4.55.4</option><option value=\"5\">v4.53.3</option><option value=\"6\">v4.52.3</option><option value=\"7\">v4.51.3</option><option value=\"8\">v4.50.0</option><option value=\"9\">v4.49.0</option><option value=\"10\">v4.48.2</option><option value=\"11\">v4.47.1</option><option value=\"12\">v4.46.3</option><option value=\"13\">v4.45.2</option><option value=\"14\">v4.44.2</option><option value=\"15\">v4.43.4</option><option value=\"16\">v4.42.4</option><option value=\"17\">v4.41.2</option><option value=\"18\">v4.40.2</option><option value=\"19\">v4.39.3</option><option value=\"20\">v4.38.2</option><option value=\"21\">v4.37.2</option><option value=\"22\">v4.36.1</option><option value=\"23\">v4.35.2</option><option value=\"24\">v4.34.1</option><option value=\"25\">v4.33.3</option><option value=\"26\">v4.32.1</option><option value=\"27\">v4.31.0</option><option value=\"28\">v4.30.0</option><option value=\"29\">v4.29.1</option><option value=\"30\">v4.28.1</option><option value=\"31\">v4.27.2</option><option value=\"32\">v4.26.1</option><option value=\"33\">v4.25.1</option><option value=\"34\">v4.24.0</option><option value=\"35\">v4.23.1</option><option value=\"36\">v4.22.2</option><option value=\"37\">v4.21.3</option><option value=\"38\">v4.20.1</option><option value=\"39\">v4.19.4</option><option value=\"40\">v4.18.0</option><option value=\"41\">v4.17.0</option><option value=\"42\">v4.16.2</option><option value=\"43\">v4.15.0</option><option value=\"44\">v4.14.1</option><option value=\"45\">v4.13.0</option><option value=\"46\">v4.12.5</option><option value=\"47\">v4.11.3</option><option value=\"48\">v4.10.1</option><option value=\"49\">v4.9.2</option><option value=\"50\">v4.8.2</option><option value=\"51\">v4.7.0</option><option value=\"52\">v4.6.0</option><option value=\"53\">v4.5.1</option><option value=\"54\">v4.4.2</option><option value=\"55\">v4.3.3</option><option value=\"56\">v4.2.2</option><option value=\"57\">v4.1.1</option><option value=\"58\">v4.0.1</option><option value=\"59\">v3.5.1</option><option value=\"60\">v3.4.0</option><option value=\"61\">v3.3.1</option><option value=\"62\">v3.2.0</option><option value=\"63\">v3.1.0</option><option value=\"64\">v3.0.2</option><option value=\"65\">v2.11.0</option><option value=\"66\">v2.10.0</option><option value=\"67\">v2.9.1</option><option value=\"68\">v2.8.0</option><option value=\"69\">v2.7.0</option><option value=\"70\">v2.6.0</option><option value=\"71\">v2.5.1</option><option value=\"72\">v2.4.1</option><option value=\"73\">v2.3.0</option><option value=\"74\">v2.2.2</option><option value=\"75\">v2.1.1</option><option value=\"76\">v2.0.0</option><option value=\"77\">v1.2.0</option><option value=\"78\">v1.1.0</option><option value=\"79\">v1.0.0</option><option value=\"80\">doc-builder-html</option></select>\n<select class=\"form-input dark:text-gray-400! mr-1 rounded-sm border-gray-200 p-1 text-xs w-12! mt-0! border!\"><option value=\"ar\">AR</option><option value=\"de\">DE</option><option selected=\"\" value=\"en\">EN</option><option value=\"es\">ES</option><option value=\"fr\">FR</option><option value=\"hi\">HI</option><option value=\"it\">IT</option><option value=\"ja\">JA</option><option value=\"ko\">KO</option><option value=\"pt\">PT</option><option value=\"zh\">ZH</option></select>\n<div class=\"relative inline-block\">\n<button class=\"rounded-full border border-gray-100 pl-2 py-1 pr-2.5 flex items-center text-sm text-gray-500 bg-white hover:bg-yellow-50 hover:border-yellow-200 dark:hover:bg-gray-800 dark:hover:border-gray-950 dark:border-gray-800\" type=\"button\">\n<svg aria-hidden=\"true\" class=\"text-yellow-500\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M6.05 4.14l-.39-.39a.993.993 0 0 0-1.4 0l-.01.01a.984.984 0 0 0 0 1.4l.39.39c.39.39 1.01.39 1.4 0l.01-.01a.984.984 0 0 0 0-1.4zM3.01 10.5H1.99c-.55 0-.99.44-.99.99v.01c0 .55.44.99.99.99H3c.56.01 1-.43 1-.98v-.01c0-.56-.44-1-.99-1zm9-9.95H12c-.56 0-1 .44-1 .99v.96c0 .55.44.99.99.99H12c.56.01 1-.43 1-.98v-.97c0-.55-.44-.99-.99-.99zm7.74 3.21c-.39-.39-1.02-.39-1.41-.01l-.39.39a.984.984 0 0 0 0 1.4l.01.01c.39.39 1.02.39 1.4 0l.39-.39a.984.984 0 0 0 0-1.4zm-1.81 15.1l.39.39a.996.996 0 1 0 1.41-1.41l-.39-.39a.993.993 0 0 0-1.4 0c-.4.4-.4 1.02-.01 1.41zM20 11.49v.01c0 .55.44.99.99.99H22c.55 0 .99-.44.99-.99v-.01c0-.55-.44-.99-.99-.99h-1.01c-.55 0-.99.44-.99.99zM12 5.5c-3.31 0-6 2.69-6 6s2.69 6 6 6s6-2.69 6-6s-2.69-6-6-6zm-.01 16.95H12c.55 0 .99-.44.99-.99v-.96c0-.55-.44-.99-.99-.99h-.01c-.55 0-.99.44-.99.99v.96c0 .55.44.99.99.99zm-7.74-3.21c.39.39 1.02.39 1.41 0l.39-.39a.993.993 0 0 0 0-1.4l-.01-.01a.996.996 0 0 0-1.41 0l-.39.39c-.38.4-.38 1.02.01 1.41z\"></path></svg>\n</button>\n</div>\n<div class=\"ml-auto flex items-center gap-x-2.5\">\n<a class=\"group text-xs text-gray-500 hover:text-gray-700 hover:underline dark:hover:text-gray-300\" href=\"https://github.com/huggingface/transformers\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"inline-block text-gray-500 group-hover:text-gray-700 dark:group-hover:text-gray-300 mr-0.5 -mt-1 size-3\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 250\" width=\"1.03em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M128.001 0C57.317 0 0 57.307 0 128.001c0 56.554 36.676 104.535 87.535 121.46c6.397 1.185 8.746-2.777 8.746-6.158c0-3.052-.12-13.135-.174-23.83c-35.61 7.742-43.124-15.103-43.124-15.103c-5.823-14.795-14.213-18.73-14.213-18.73c-11.613-7.944.876-7.78.876-7.78c12.853.902 19.621 13.19 19.621 13.19c11.417 19.568 29.945 13.911 37.249 10.64c1.149-8.272 4.466-13.92 8.127-17.116c-28.431-3.236-58.318-14.212-58.318-63.258c0-13.975 5-25.394 13.188-34.358c-1.329-3.224-5.71-16.242 1.24-33.874c0 0 10.749-3.44 35.21 13.121c10.21-2.836 21.16-4.258 32.038-4.307c10.878.049 21.837 1.47 32.066 4.307c24.431-16.56 35.165-13.12 35.165-13.12c6.967 17.63 2.584 30.65 1.255 33.873c8.207 8.964 13.173 20.383 13.173 34.358c0 49.163-29.944 59.988-58.447 63.157c4.591 3.972 8.682 11.762 8.682 23.704c0 17.126-.148 30.91-.148 35.126c0 3.407 2.304 7.398 8.792 6.14C219.37 232.5 256 184.537 256 128.002C256 57.307 198.691 0 128.001 0zm-80.06 182.34c-.282.636-1.283.827-2.194.39c-.929-.417-1.45-1.284-1.15-1.922c.276-.655 1.279-.838 2.205-.399c.93.418 1.46 1.293 1.139 1.931zm6.296 5.618c-.61.566-1.804.303-2.614-.591c-.837-.892-.994-2.086-.375-2.66c.63-.566 1.787-.301 2.626.591c.838.903 1 2.088.363 2.66zm4.32 7.188c-.785.545-2.067.034-2.86-1.104c-.784-1.138-.784-2.503.017-3.05c.795-.547 2.058-.055 2.861 1.075c.782 1.157.782 2.522-.019 3.08zm7.304 8.325c-.701.774-2.196.566-3.29-.49c-1.119-1.032-1.43-2.496-.726-3.27c.71-.776 2.213-.558 3.315.49c1.11 1.03 1.45 2.505.701 3.27zm9.442 2.81c-.31 1.003-1.75 1.459-3.199 1.033c-1.448-.439-2.395-1.613-2.103-2.626c.301-1.01 1.747-1.484 3.207-1.028c1.446.436 2.396 1.602 2.095 2.622zm10.744 1.193c.036 1.055-1.193 1.93-2.715 1.95c-1.53.034-2.769-.82-2.786-1.86c0-1.065 1.202-1.932 2.733-1.958c1.522-.03 2.768.818 2.768 1.868zm10.555-.405c.182 1.03-.875 2.088-2.387 2.37c-1.485.271-2.861-.365-3.05-1.386c-.184-1.056.893-2.114 2.376-2.387c1.514-.263 2.868.356 3.061 1.403z\" fill=\"currentColor\"></path></svg>\n</a></div></div></div>\n</div></div></div>\n<div class=\"z-1 min-w-0 flex-1\">\n<div class=\"px-6 pt-6 md:px-12 md:pb-16 md:pt-16\"><div class=\"max-w-4xl mx-auto mb-10\"><div class=\"bg-linear-to-br relative overflow-hidden rounded-xl from-orange-300/10 px-4 py-5 ring-1 ring-orange-100/70 md:px-6 md:py-8\"><img alt=\"Hugging Face's logo\" class=\"absolute -bottom-6 -right-6 w-28 -rotate-45 md:hidden\" src=\"https://huggingface.co/front/assets/huggingface_logo-noborder.svg\"/>\n<div class=\"mb-2 text-2xl font-bold dark:text-gray-200 md:mb-0\">Join the Hugging Face community</div>\n<p class=\"mb-4 text-lg text-gray-400 dark:text-gray-300 md:mb-8\">and get access to the augmented documentation experience\n\t\t</p>\n<div class=\"mb-8 hidden space-y-4 md:block xl:flex xl:space-x-6 xl:space-y-0\"><div class=\"flex items-center\"><div class=\"bg-linear-to-br mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg from-indigo-100 to-indigo-100/20 dark:to-indigo-100\"><svg aria-hidden=\"true\" class=\"text-indigo-400 group-hover:text-indigo-500\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" style=\"\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path class=\"uim-quaternary\" d=\"M20.23 7.24L12 12L3.77 7.24a1.98 1.98 0 0 1 .7-.71L11 2.76c.62-.35 1.38-.35 2 0l6.53 3.77c.29.173.531.418.7.71z\" fill=\"currentColor\" opacity=\".25\"></path><path class=\"uim-tertiary\" d=\"M12 12v9.5a2.09 2.09 0 0 1-.91-.21L4.5 17.48a2.003 2.003 0 0 1-1-1.73v-7.5a2.06 2.06 0 0 1 .27-1.01L12 12z\" fill=\"currentColor\" opacity=\".5\"></path><path class=\"uim-primary\" d=\"M20.5 8.25v7.5a2.003 2.003 0 0 1-1 1.73l-6.62 3.82c-.275.13-.576.198-.88.2V12l8.23-4.76c.175.308.268.656.27 1.01z\" fill=\"currentColor\"></path></svg></div>\n<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Collaborate on models, datasets and Spaces\n\t\t\t\t</div></div>\n<div class=\"flex items-center\"><div class=\"bg-linear-to-br mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg from-orange-100 to-orange-100/20 dark:to-orange-50\"><svg aria-hidden=\"true\" class=\"text-xl text-yellow-400\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M11 15H6l7-14v8h5l-7 14v-8z\" fill=\"currentColor\"></path></svg></div>\n<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Faster examples with accelerated inference\n\t\t\t\t</div></div>\n<div class=\"flex items-center\"><div class=\"bg-linear-to-br mr-3 flex h-9 w-9 flex-none items-center justify-center rounded-lg from-gray-500/10 to-gray-500/5\"><svg aria-hidden=\"true\" class=\"text-gray-400\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M14.9804 3C14.9217 3.0002 14.8631 3.00555 14.8054 3.016C11.622 3.58252 8.76073 5.30669 6.77248 7.85653C4.78422 10.4064 3.80955 13.6016 4.03612 16.8271C4.26268 20.0525 5.67447 23.0801 7.99967 25.327C10.3249 27.5738 13.3991 28.8811 16.6304 28.997C16.7944 29.003 16.9584 28.997 17.1204 28.997C19.2193 28.9984 21.2877 28.4943 23.1507 27.5274C25.0137 26.5605 26.6164 25.1592 27.8234 23.442C27.9212 23.294 27.9783 23.1229 27.9889 22.9458C27.9995 22.7687 27.9633 22.592 27.884 22.4333C27.8046 22.2747 27.6848 22.1397 27.5367 22.0421C27.3887 21.9444 27.2175 21.8875 27.0404 21.877C25.0426 21.7017 23.112 21.0693 21.3976 20.0288C19.6832 18.9884 18.231 17.5676 17.1533 15.8764C16.0756 14.1852 15.4011 12.2688 15.1822 10.2754C14.9632 8.28193 15.2055 6.26484 15.8904 4.38C15.9486 4.22913 15.97 4.06652 15.9527 3.90572C15.9354 3.74492 15.8799 3.59059 15.7909 3.45557C15.7019 3.32055 15.5819 3.20877 15.4409 3.12952C15.2999 3.05028 15.142 3.00587 14.9804 3Z\" fill=\"currentColor\"></path></svg></div>\n<div class=\"text-smd leading-tight text-gray-500 dark:text-gray-300 xl:max-w-[200px] 2xl:text-base\">Switch between documentation themes\n\t\t\t\t</div></div></div>\n<div class=\"flex items-center space-x-2.5\"><a href=\"https://huggingface.co/join\" target=\"_blank\"><button class=\"bg-linear-to-br shadow-xs rounded-lg bg-white from-gray-100/20 to-gray-200/60 px-5 py-1.5 font-semibold text-gray-700 ring-1 ring-gray-300/60 hover:to-gray-100/70 hover:ring-gray-300/30 active:shadow-inner\">Sign Up</button></a>\n<p class=\"text-gray-500 dark:text-gray-300\">to get started</p></div></div></div>\n<div class=\"prose-doc prose relative mx-auto max-w-4xl break-words\"><!-- HTML_TAG_START --> <link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/assets/0.e3b0c442.css\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/entry/start.1aac1e87.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/scheduler.31fdf58d.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/singletons.5234e431.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/index.252883d5.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/paths.8fd3f9cf.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/entry/app.c42f6e2a.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/preload-helper.c5e9442a.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/index.2f76fdf0.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/nodes/0.d260c662.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/each.e59479a4.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/nodes/52.64516586.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/CopyLLMTxtMenu.cf913c76.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/MermaidChart.svelte_svelte_type_style_lang.de7e2659.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/IconCopy.ac192424.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/CodeBlock.ab12f8e1.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/DocNotebookDropdown.dd28433e.js\" rel=\"modulepreload\"/>\n<link href=\"/docs/transformers/v5.0.0rc1/en/_app/immutable/chunks/HfOption.fb051768.js\" rel=\"modulepreload\"/><!-- HEAD_svelte-u9bgzb_START --><meta content='{\"title\":\"Text generation\",\"local\":\"text-generation\",\"sections\":[{\"title\":\"Default generate\",\"local\":\"default-generate\",\"sections\":[],\"depth\":2},{\"title\":\"Generation configuration\",\"local\":\"generation-configuration\",\"sections\":[{\"title\":\"Saving\",\"local\":\"saving\",\"sections\":[],\"depth\":3}],\"depth\":2},{\"title\":\"Common Options\",\"local\":\"common-options\",\"sections\":[],\"depth\":2},{\"title\":\"Pitfalls\",\"local\":\"pitfalls\",\"sections\":[{\"title\":\"Output length\",\"local\":\"output-length\",\"sections\":[],\"depth\":3},{\"title\":\"Decoding strategy\",\"local\":\"decoding-strategy\",\"sections\":[],\"depth\":3},{\"title\":\"Padding side\",\"local\":\"padding-side\",\"sections\":[],\"depth\":3},{\"title\":\"Prompt format\",\"local\":\"prompt-format\",\"sections\":[],\"depth\":3}],\"depth\":2},{\"title\":\"Resources\",\"local\":\"resources\",\"sections\":[],\"depth\":2}],\"depth\":1}' name=\"hf:doc:metadata\"/><!-- HEAD_svelte-u9bgzb_END --> <p></p> <div class=\"items-center shrink-0 min-w-[100px] max-sm:min-w-[50px] justify-end ml-auto flex\" style=\"float: right; margin-left: 10px; display: inline-flex; position: relative; z-index: 10;\"><div class=\"inline-flex rounded-md max-sm:rounded-sm\"><button aria-live=\"polite\" class=\"inline-flex items-center gap-1 max-sm:gap-0.5 h-6 max-sm:h-5 px-2 max-sm:px-1.5 text-[11px] max-sm:text-[9px] font-medium text-gray-800 border border-r-0 rounded-l-md max-sm:rounded-l-sm border-gray-200 bg-white hover:shadow-inner dark:border-gray-850 dark:bg-gray-950 dark:text-gray-200 dark:hover:bg-gray-800\"><span class=\"inline-flex items-center justify-center rounded-md p-0.5 max-sm:p-0\"><svg aria-hidden=\"true\" class=\"w-3 h-3 max-sm:w-2.5 max-sm:h-2.5\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg></span> <span>Copy page</span></button> <button aria-expanded=\"false\" aria-haspopup=\"menu\" aria-label=\"Open copy menu\" class=\"inline-flex items-center justify-center w-6 max-sm:w-5 h-6 max-sm:h-5 disabled:pointer-events-none text-sm text-gray-500 hover:text-gray-700 dark:hover:text-white rounded-r-md max-sm:rounded-r-sm border border-l transition border-gray-200 bg-white hover:shadow-inner dark:border-gray-850 dark:bg-gray-950 dark:text-gray-200 dark:hover:bg-gray-800\"><svg class=\"transition-transform text-gray-400 overflow-visible w-3 h-3 max-sm:w-2.5 max-sm:h-2.5 rotate-0\" fill=\"none\" height=\"1em\" viewbox=\"0 0 12 7\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M1 1L6 6L11 1\" stroke=\"currentColor\"></path></svg></button></div> </div> <div class=\"flex space-x-1\" style=\"float: right; margin-left: 10px; display: inline-flex; position: relative; z-index: 10;\"> <div class=\"relative colab-dropdown\"> <button class=\"\" type=\"button\"> <img alt=\"Open In Colab\" class=\"!m-0\" src=\"https://colab.research.google.com/assets/colab-badge.svg\"/> </button> </div> <div class=\"relative colab-dropdown\"> <button class=\"\" type=\"button\"> <img alt=\"Open In Studio Lab\" class=\"!m-0\" src=\"https://studiolab.sagemaker.aws/studiolab.svg\"/> </button> </div></div> <h1 class=\"relative group\"><a class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"https://huggingface.co/docs/transformers/llm_tutorial#text-generation\" id=\"text-generation\" target=\"_blank\"><span><svg aria-hidden=\"true\" class=\"\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Text generation</span></h1> <p data-svelte-h=\"svelte-s7iru1\">Text generation is the most popular application for large language models (LLMs). A LLM is trained to generate the next word (token) given some initial text (prompt) along with its own generated outputs up to a predefined length or when it reaches an end-of-sequence (<code>EOS</code>) token.</p> <p data-svelte-h=\"svelte-10ja7uw\">In Transformers, the <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationMixin.generate\" target=\"_blank\">generate()</a> API handles text generation, and it is available for all models with generative capabilities. This guide will show you the basics of text generation with <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationMixin.generate\" target=\"_blank\">generate()</a> and some common pitfalls to avoid.</p> <blockquote class=\"tip\"><p data-svelte-h=\"svelte-h2py01\">For the following commands, please make sure <a href=\"https://huggingface.co/docs/transformers/main/en/serving\" rel=\"nofollow\" target=\"_blank\"><code>transformers serve</code> is running</a>.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->transformers chat Qwen/Qwen2.5-0.5B-Instruct<!-- HTML_TAG_END --></pre></div></blockquote> <h2 class=\"relative group\"><a class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"https://huggingface.co/docs/transformers/llm_tutorial#default-generate\" id=\"default-generate\" target=\"_blank\"><span><svg aria-hidden=\"true\" class=\"\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Default generate</span></h2> <p data-svelte-h=\"svelte-yt64tx\">Before you begin, itâs helpful to install <a href=\"https://hf.co/docs/bitsandbytes/index\" rel=\"nofollow\" target=\"_blank\">bitsandbytes</a> to quantize really large models to reduce their memory usage.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->!pip install -U transformers bitsandbytes<!-- HTML_TAG_END --></pre></div> <p data-svelte-h=\"svelte-1wjvkti\">Bitsandbytes supports multiple backends in addition to CUDA-based GPUs. Refer to the multi-backend installation <a href=\"https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\" rel=\"nofollow\" target=\"_blank\">guide</a> to learn more.</p> <p data-svelte-h=\"svelte-rte62z\">Load a LLM with <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/model#transformers.PreTrainedModel.from_pretrained\" target=\"_blank\">from_pretrained()</a> and add the following two parameters to reduce the memory requirements.</p> <ul data-svelte-h=\"svelte-1dhu4u9\"><li><code>device_map=\"auto\"</code> enables Acceleratesâ <a href=\"https://huggingface.co/docs/transformers/models#big-model-inference\" target=\"_blank\">Big Model Inference</a> feature for automatically initiating the model skeleton and loading and dispatching the model weights across all available devices, starting with the fastest device (GPU).</li> <li><code>quantization_config</code> is a configuration object that defines the quantization settings. This examples uses bitsandbytes as the quantization backend (see the <a href=\"https://huggingface.co/docs/transformers/quantization/overview\" target=\"_blank\">Quantization</a> section for more available backends) and it loads the model in <a href=\"https://huggingface.co/docs/transformers/quantization/bitsandbytes\" target=\"_blank\">4-bits</a>.</li></ul> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START --><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nquantization_config = BitsAndBytesConfig(load_in_4bit=<span class=\"hljs-literal\">True</span>)\nmodel = AutoModelForCausalLM.from_pretrained(<span class=\"hljs-string\">\"mistralai/Mistral-7B-v0.1\"</span>, device_map=<span class=\"hljs-string\">\"auto\"</span>, quantization_config=quantization_config)<!-- HTML_TAG_END --></pre></div> <p data-svelte-h=\"svelte-17s8xst\">Tokenize your input, and set the <code>padding_side()</code> parameter to <code>\"left\"</code> because a LLM is not trained to continue generation from padding tokens. The tokenizer returns the input ids and attention mask.</p> <blockquote class=\"tip\" data-svelte-h=\"svelte-1yb2m48\"><p>Process more than one prompt at a time by passing a list of strings to the tokenizer. Batch the inputs to improve throughput at a small cost to latency and memory.</p></blockquote> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->tokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"mistralai/Mistral-7B-v0.1\"</span>, padding_side=<span class=\"hljs-string\">\"left\"</span>)\nmodel_inputs = tokenizer([<span class=\"hljs-string\">\"A list of colors: red, blue\"</span>], return_tensors=<span class=\"hljs-string\">\"pt\"</span>).to(model.device)<!-- HTML_TAG_END --></pre></div> <p data-svelte-h=\"svelte-a26egf\">Pass the inputs to <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationMixin.generate\" target=\"_blank\">generate()</a> to generate tokens, and <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/internal/tokenization_utils#transformers.PreTrainedTokenizerBase.batch_decode\" target=\"_blank\">batch_decode()</a> the generated tokens back to text.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->generated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=<span class=\"hljs-literal\">True</span>)[<span class=\"hljs-number\">0</span>]\n<span class=\"hljs-string\">\"A list of colors: red, blue, green, yellow, orange, purple, pink,\"</span><!-- HTML_TAG_END --></pre></div> <h2 class=\"relative group\"><a class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"https://huggingface.co/docs/transformers/llm_tutorial#generation-configuration\" id=\"generation-configuration\" target=\"_blank\"><span><svg aria-hidden=\"true\" class=\"\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Generation configuration</span></h2> <p data-svelte-h=\"svelte-1rtcnm5\">All generation settings are contained in <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationConfig\" target=\"_blank\">GenerationConfig</a>. In the example above, the generation settings are derived from the <code>generation_config.json</code> file of <a href=\"https://huggingface.co/mistralai/Mistral-7B-v0.1\" rel=\"nofollow\" target=\"_blank\">mistralai/Mistral-7B-v0.1</a>. A default decoding strategy is used when no configuration is saved with a model.</p> <p data-svelte-h=\"svelte-10rprr6\">Inspect the configuration through the <code>generation_config</code> attribute. It only shows values that are different from the default configuration, in this case, the <code>bos_token_id</code> and <code>eos_token_id</code>.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START --><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(<span class=\"hljs-string\">\"mistralai/Mistral-7B-v0.1\"</span>, device_map=<span class=\"hljs-string\">\"auto\"</span>)\nmodel.generation_config\nGenerationConfig {\n  <span class=\"hljs-string\">\"bos_token_id\"</span>: <span class=\"hljs-number\">1</span>,\n  <span class=\"hljs-string\">\"eos_token_id\"</span>: <span class=\"hljs-number\">2</span>\n}<!-- HTML_TAG_END --></pre></div> <p data-svelte-h=\"svelte-s0ejoj\">You can customize <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationMixin.generate\" target=\"_blank\">generate()</a> by overriding the parameters and values in <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationConfig\" target=\"_blank\">GenerationConfig</a>. See <a href=\"https://huggingface.co/docs/transformers/llm_tutorial#common-options\" target=\"_blank\">this section below</a> for commonly adjusted parameters.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START --><span class=\"hljs-comment\"># enable beam search sampling strategy</span>\nmodel.generate(**inputs, num_beams=<span class=\"hljs-number\">4</span>, do_sample=<span class=\"hljs-literal\">True</span>)<!-- HTML_TAG_END --></pre></div> <p data-svelte-h=\"svelte-1tc6g8v\"><a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationMixin.generate\" target=\"_blank\">generate()</a> can also be extended with external libraries or custom code:</p> <ol data-svelte-h=\"svelte-1w5bevz\"><li>the <code>logits_processor</code> parameter accepts custom <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/internal/generation_utils#transformers.LogitsProcessor\" target=\"_blank\">LogitsProcessor</a> instances for manipulating the next token probability distribution;</li> <li>the <code>stopping_criteria</code> parameters supports custom <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/internal/generation_utils#transformers.StoppingCriteria\" target=\"_blank\">StoppingCriteria</a> to stop text generation;</li> <li>other custom generation methods can be loaded through the <code>custom_generate</code> flag (<a href=\"https://huggingface.co/docs/transformers/generation_strategies.md/#custom-decoding-methods\" target=\"_blank\">docs</a>).</li></ol> <p data-svelte-h=\"svelte-h59t1w\">Refer to the <a href=\"https://huggingface.co/docs/transformers/generation_strategies\" target=\"_blank\">Generation strategies</a> guide to learn more about search, sampling, and decoding strategies.</p> <h3 class=\"relative group\"><a class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"https://huggingface.co/docs/transformers/llm_tutorial#saving\" id=\"saving\" target=\"_blank\"><span><svg aria-hidden=\"true\" class=\"\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Saving</span></h3> <p data-svelte-h=\"svelte-9j3b3h\">Create an instance of <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationConfig\" target=\"_blank\">GenerationConfig</a> and specify the decoding parameters you want.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START --><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoModelForCausalLM, GenerationConfig\n\nmodel = AutoModelForCausalLM.from_pretrained(<span class=\"hljs-string\">\"my_account/my_model\"</span>)\ngeneration_config = GenerationConfig(\n    max_new_tokens=<span class=\"hljs-number\">50</span>, do_sample=<span class=\"hljs-literal\">True</span>, top_k=<span class=\"hljs-number\">50</span>, eos_token_id=model.config.eos_token_id\n)<!-- HTML_TAG_END --></pre></div> <p data-svelte-h=\"svelte-1r4vmby\">Use <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationConfig.save_pretrained\" target=\"_blank\">save_pretrained()</a> to save a specific generation configuration and set the <code>push_to_hub</code> parameter to <code>True</code> to upload it to the Hub.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->generation_config.save_pretrained(<span class=\"hljs-string\">\"my_account/my_model\"</span>, push_to_hub=<span class=\"hljs-literal\">True</span>)<!-- HTML_TAG_END --></pre></div> <p data-svelte-h=\"svelte-wh0tr3\">Leave the <code>config_file_name</code> parameter empty. This parameter should be used when storing multiple generation configurations in a single directory. It gives you a way to specify which generation configuration to load. You can create different configurations for different generative tasks (creative text generation with sampling, summarization with beam search) for use with a single model.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START --><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig\n\ntokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"google-t5/t5-small\"</span>)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(<span class=\"hljs-string\">\"google-t5/t5-small\"</span>)\n\ntranslation_generation_config = GenerationConfig(\n    num_beams=<span class=\"hljs-number\">4</span>,\n    early_stopping=<span class=\"hljs-literal\">True</span>,\n    decoder_start_token_id=<span class=\"hljs-number\">0</span>,\n    eos_token_id=model.config.eos_token_id,\n    pad_token=model.config.pad_token_id,\n)\n\ntranslation_generation_config.save_pretrained(<span class=\"hljs-string\">\"/tmp\"</span>, config_file_name=<span class=\"hljs-string\">\"translation_generation_config.json\"</span>, push_to_hub=<span class=\"hljs-literal\">True</span>)\n\ngeneration_config = GenerationConfig.from_pretrained(<span class=\"hljs-string\">\"/tmp\"</span>, config_file_name=<span class=\"hljs-string\">\"translation_generation_config.json\"</span>)\ninputs = tokenizer(<span class=\"hljs-string\">\"translate English to French: Configuration files are easy to use!\"</span>, return_tensors=<span class=\"hljs-string\">\"pt\"</span>)\noutputs = model.generate(**inputs, generation_config=generation_config)\n<span class=\"hljs-built_in\">print</span>(tokenizer.batch_decode(outputs, skip_special_tokens=<span class=\"hljs-literal\">True</span>))<!-- HTML_TAG_END --></pre></div> <h2 class=\"relative group\"><a class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"https://huggingface.co/docs/transformers/llm_tutorial#common-options\" id=\"common-options\" target=\"_blank\"><span><svg aria-hidden=\"true\" class=\"\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Common Options</span></h2> <p data-svelte-h=\"svelte-moypcp\"><a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationMixin.generate\" target=\"_blank\">generate()</a> is a powerful tool that can be heavily customized. This can be daunting for a new users. This section contains a list of popular generation options that you can define in most text generation tools in Transformers: <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationMixin.generate\" target=\"_blank\">generate()</a>, <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationConfig\" target=\"_blank\">GenerationConfig</a>, <code>pipelines</code>, the <code>chat</code> CLI, â¦</p> <table data-svelte-h=\"svelte-p4fnc8\"><thead><tr><th>Option name</th> <th>Type</th> <th>Simplified description</th></tr></thead> <tbody><tr><td><code>max_new_tokens</code></td> <td><code>int</code></td> <td>Controls the maximum generation length. Be sure to define it, as it usually defaults to a small value.</td></tr> <tr><td><code>do_sample</code></td> <td><code>bool</code></td> <td>Defines whether generation will sample the next token (<code>True</code>), or is greedy instead (<code>False</code>). Most use cases should set this flag to <code>True</code>. Check <a href=\"https://huggingface.co/docs/transformers/generation_strategies\" target=\"_blank\">this guide</a> for more information.</td></tr> <tr><td><code>temperature</code></td> <td><code>float</code></td> <td>How unpredictable the next selected token will be. High values (<code>&gt;0.8</code>) are good for creative tasks, low values (e.g. <code>&lt;0.4</code>) for tasks that require âthinkingâ. Requires <code>do_sample=True</code>.</td></tr> <tr><td><code>num_beams</code></td> <td><code>int</code></td> <td>When set to <code>&gt;1</code>, activates the beam search algorithm. Beam search is good on input-grounded tasks. Check <a href=\"https://huggingface.co/docs/transformers/generation_strategies\" target=\"_blank\">this guide</a> for more information.</td></tr> <tr><td><code>repetition_penalty</code></td> <td><code>float</code></td> <td>Set it to <code>&gt;1.0</code> if youâre seeing the model repeat itself often. Larger values apply a larger penalty.</td></tr> <tr><td><code>eos_token_id</code></td> <td><code>list[int]</code></td> <td>The token(s) that will cause generation to stop. The default value is usually good, but you can specify a different token.</td></tr></tbody></table> <h2 class=\"relative group\"><a class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"https://huggingface.co/docs/transformers/llm_tutorial#pitfalls\" id=\"pitfalls\" target=\"_blank\"><span><svg aria-hidden=\"true\" class=\"\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Pitfalls</span></h2> <p data-svelte-h=\"svelte-1m2m0f4\">The section below covers some common issues you may encounter during text generation and how to solve them.</p> <h3 class=\"relative group\"><a class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"https://huggingface.co/docs/transformers/llm_tutorial#output-length\" id=\"output-length\" target=\"_blank\"><span><svg aria-hidden=\"true\" class=\"\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Output length</span></h3> <p data-svelte-h=\"svelte-1ijtdbe\"><a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationMixin.generate\" target=\"_blank\">generate()</a> returns up to 20 tokens by default unless otherwise specified in a models <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationConfig\" target=\"_blank\">GenerationConfig</a>. It is highly recommended to manually set the number of generated tokens with the <code>max_new_tokens</code> parameter to control the output length. <a href=\"https://hf.co/learn/nlp-course/chapter1/6?fw=pt\" rel=\"nofollow\" target=\"_blank\">Decoder-only</a> models returns the initial prompt along with the generated tokens.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->model_inputs = tokenizer([<span class=\"hljs-string\">\"A sequence of numbers: 1, 2\"</span>], return_tensors=<span class=\"hljs-string\">\"pt\"</span>).to(model.device)<!-- HTML_TAG_END --></pre></div> <div class=\"flex space-x-2 items-center my-1.5 mr-8 h-7 !pl-0 -mx-3 md:mx-0\"><div class=\"flex items-center border rounded-lg px-1.5 py-1 leading-none select-none text-smd border-gray-800 bg-black dark:bg-gray-700 text-white\">default length </div><div class=\"flex items-center border rounded-lg px-1.5 py-1 leading-none select-none text-smd text-gray-500 cursor-pointer opacity-90 hover:text-gray-700 dark:hover:text-gray-200 hover:shadow-sm\">max_new_tokens </div></div> <div class=\"language-select\"><div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->generated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=<span class=\"hljs-literal\">True</span>)[<span class=\"hljs-number\">0</span>]\n<span class=\"hljs-string\">'A sequence of numbers: 1, 2, 3, 4, 5'</span><!-- HTML_TAG_END --></pre></div> </div> <h3 class=\"relative group\"><a class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"https://huggingface.co/docs/transformers/llm_tutorial#decoding-strategy\" id=\"decoding-strategy\" target=\"_blank\"><span><svg aria-hidden=\"true\" class=\"\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Decoding strategy</span></h3> <p data-svelte-h=\"svelte-ip2ks1\">The default decoding strategy in <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationMixin.generate\" target=\"_blank\">generate()</a> is <em>greedy search</em>, which selects the next most likely token, unless otherwise specified in a models <a href=\"https://huggingface.co/docs/transformers/v5.0.0rc1/en/main_classes/text_generation#transformers.GenerationConfig\" target=\"_blank\">GenerationConfig</a>. While this decoding strategy works well for input-grounded tasks (transcription, translation), it is not optimal for more creative use cases (story writing, chat applications).</p> <p data-svelte-h=\"svelte-doqzfm\">For example, enable a <a href=\"https://huggingface.co/docs/transformers/generation_strategies#multinomial-sampling\" target=\"_blank\">multinomial sampling</a> strategy to generate more diverse outputs. Refer to the <a href=\"https://huggingface.co/docs/transformers/generation_strategies\" target=\"_blank\">Generation strategy</a> guide for more decoding strategies.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->model_inputs = tokenizer([<span class=\"hljs-string\">\"I am a cat.\"</span>], return_tensors=<span class=\"hljs-string\">\"pt\"</span>).to(model.device)<!-- HTML_TAG_END --></pre></div> <div class=\"flex space-x-2 items-center my-1.5 mr-8 h-7 !pl-0 -mx-3 md:mx-0\"><div class=\"flex items-center border rounded-lg px-1.5 py-1 leading-none select-none text-smd border-gray-800 bg-black dark:bg-gray-700 text-white\">greedy search </div><div class=\"flex items-center border rounded-lg px-1.5 py-1 leading-none select-none text-smd text-gray-500 cursor-pointer opacity-90 hover:text-gray-700 dark:hover:text-gray-200 hover:shadow-sm\">multinomial sampling </div></div> <div class=\"language-select\"><div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->generated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=<span class=\"hljs-literal\">True</span>)[<span class=\"hljs-number\">0</span>]<!-- HTML_TAG_END --></pre></div> </div> <h3 class=\"relative group\"><a class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"https://huggingface.co/docs/transformers/llm_tutorial#padding-side\" id=\"padding-side\" target=\"_blank\"><span><svg aria-hidden=\"true\" class=\"\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Padding side</span></h3> <p data-svelte-h=\"svelte-1sb2pzh\">Inputs need to be padded if they donât have the same length. But LLMs arenât trained to continue generation from padding tokens, which means the <code>padding_side()</code> parameter needs to be set to the left of the input.</p> <div class=\"flex space-x-2 items-center my-1.5 mr-8 h-7 !pl-0 -mx-3 md:mx-0\"><div class=\"flex items-center border rounded-lg px-1.5 py-1 leading-none select-none text-smd border-gray-800 bg-black dark:bg-gray-700 text-white\">right pad </div><div class=\"flex items-center border rounded-lg px-1.5 py-1 leading-none select-none text-smd text-gray-500 cursor-pointer opacity-90 hover:text-gray-700 dark:hover:text-gray-200 hover:shadow-sm\">left pad </div></div> <div class=\"language-select\"><div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->model_inputs = tokenizer(\n    [<span class=\"hljs-string\">\"1, 2, 3\"</span>, <span class=\"hljs-string\">\"A, B, C, D, E\"</span>], padding=<span class=\"hljs-literal\">True</span>, return_tensors=<span class=\"hljs-string\">\"pt\"</span>\n).to(model.device)\ngenerated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=<span class=\"hljs-literal\">True</span>)[<span class=\"hljs-number\">0</span>]\n<span class=\"hljs-string\">'1, 2, 33333333333'</span><!-- HTML_TAG_END --></pre></div> </div> <h3 class=\"relative group\"><a class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"https://huggingface.co/docs/transformers/llm_tutorial#prompt-format\" id=\"prompt-format\" target=\"_blank\"><span><svg aria-hidden=\"true\" class=\"\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Prompt format</span></h3> <p data-svelte-h=\"svelte-7oxbwr\">Some models and tasks expect a certain input prompt format, and if the format is incorrect, the model returns a suboptimal output. You can learn more about prompting in the <a href=\"https://huggingface.co/docs/transformers/tasks/prompting\" target=\"_blank\">prompt engineering</a> guide.</p> <p data-svelte-h=\"svelte-11sbjub\">For example, a chat model expects the input as a <a href=\"https://huggingface.co/docs/transformers/chat_templating\" target=\"_blank\">chat template</a>. Your prompt should include a <code>role</code> and <code>content</code> to indicate who is participating in the conversation. If you try to pass your prompt as a single string, the model doesnât always return the expected output.</p> <div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START --><span class=\"hljs-keyword\">from</span> transformers <span class=\"hljs-keyword\">import</span> AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\ntokenizer = AutoTokenizer.from_pretrained(<span class=\"hljs-string\">\"HuggingFaceH4/zephyr-7b-alpha\"</span>)\nmodel = AutoModelForCausalLM.from_pretrained(\n    <span class=\"hljs-string\">\"HuggingFaceH4/zephyr-7b-alpha\"</span>, device_map=<span class=\"hljs-string\">\"auto\"</span>, quantization_config=BitsAndBytesConfig(load_in_4bit=<span class=\"hljs-literal\">True</span>)\n)<!-- HTML_TAG_END --></pre></div> <div class=\"flex space-x-2 items-center my-1.5 mr-8 h-7 !pl-0 -mx-3 md:mx-0\"><div class=\"flex items-center border rounded-lg px-1.5 py-1 leading-none select-none text-smd border-gray-800 bg-black dark:bg-gray-700 text-white\">no format </div><div class=\"flex items-center border rounded-lg px-1.5 py-1 leading-none select-none text-smd text-gray-500 cursor-pointer opacity-90 hover:text-gray-700 dark:hover:text-gray-200 hover:shadow-sm\">chat template </div></div> <div class=\"language-select\"><div class=\"code-block relative\"><div class=\"absolute top-2.5 right-4\"><button class=\"inline-flex items-center relative text-sm focus:text-green-500 cursor-pointer focus:outline-none transition duration-200 ease-in-out opacity-0 mx-0.5 text-gray-600\" title=\"code excerpt\" type=\"button\"><svg aria-hidden=\"true\" class=\"\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M28,10V28H10V10H28m0-2H10a2,2,0,0,0-2,2V28a2,2,0,0,0,2,2H28a2,2,0,0,0,2-2V10a2,2,0,0,0-2-2Z\" transform=\"translate(0)\"></path><path d=\"M4,18H2V4A2,2,0,0,1,4,2H18V4H4Z\" transform=\"translate(0)\"></path><rect fill=\"none\" height=\"32\" width=\"32\"></rect></svg> <div class=\"absolute pointer-events-none transition-opacity bg-black text-white py-1 px-2 leading-tight rounded font-normal shadow left-1/2 top-full transform -translate-x-1/2 translate-y-2 opacity-0\"><div class=\"absolute bottom-full left-1/2 transform -translate-x-1/2 w-0 h-0 border-black border-4 border-t-0\" style=\"border-left-color: transparent; border-right-color: transparent; \"></div> Copied</div></button></div> <pre class=\"\"><!-- HTML_TAG_START -->prompt = <span class=\"hljs-string\">\"\"\"How many cats does it take to change a light bulb? Reply as a pirate.\"\"\"</span>\nmodel_inputs = tokenizer([prompt], return_tensors=<span class=\"hljs-string\">\"pt\"</span>).to(model.device)\ninput_length = model_inputs.input_ids.shape[<span class=\"hljs-number\">1</span>]\ngenerated_ids = model.generate(**model_inputs, max_new_tokens=<span class=\"hljs-number\">50</span>)\n<span class=\"hljs-built_in\">print</span>(tokenizer.batch_decode(generated_ids[:, input_length:], skip_special_tokens=<span class=\"hljs-literal\">True</span>)[<span class=\"hljs-number\">0</span>])\n<span class=\"hljs-string\">\"Aye, matey! 'Tis a simple task for a cat with a keen eye and nimble paws. First, the cat will climb up the ladder, carefully avoiding the rickety rungs. Then, with\"</span><!-- HTML_TAG_END --></pre></div> </div> <h2 class=\"relative group\"><a class=\"header-link block pr-1.5 text-lg no-hover:hidden with-hover:absolute with-hover:p-1.5 with-hover:opacity-0 with-hover:group-hover:opacity-100 with-hover:right-full\" href=\"https://huggingface.co/docs/transformers/llm_tutorial#resources\" id=\"resources\" target=\"_blank\"><span><svg aria-hidden=\"true\" class=\"\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 256 256\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><path d=\"M167.594 88.393a8.001 8.001 0 0 1 0 11.314l-67.882 67.882a8 8 0 1 1-11.314-11.315l67.882-67.881a8.003 8.003 0 0 1 11.314 0zm-28.287 84.86l-28.284 28.284a40 40 0 0 1-56.567-56.567l28.284-28.284a8 8 0 0 0-11.315-11.315l-28.284 28.284a56 56 0 0 0 79.196 79.197l28.285-28.285a8 8 0 1 0-11.315-11.314zM212.852 43.14a56.002 56.002 0 0 0-79.196 0l-28.284 28.284a8 8 0 1 0 11.314 11.314l28.284-28.284a40 40 0 0 1 56.568 56.567l-28.285 28.285a8 8 0 0 0 11.315 11.314l28.284-28.284a56.065 56.065 0 0 0 0-79.196z\" fill=\"currentColor\"></path></svg></span></a> <span>Resources</span></h2> <p data-svelte-h=\"svelte-df0me2\">Take a look below for some more specific and specialized text generation libraries.</p> <ul data-svelte-h=\"svelte-djgwfg\"><li><a href=\"https://github.com/huggingface/optimum\" rel=\"nofollow\" target=\"_blank\">Optimum</a>: an extension of Transformers focused on optimizing training and inference on specific hardware devices</li> <li><a href=\"https://github.com/dottxt-ai/outlines\" rel=\"nofollow\" target=\"_blank\">Outlines</a>: a library for constrained text generation (generate JSON files for example).</li> <li><a href=\"https://github.com/uiuc-focal-lab/syncode\" rel=\"nofollow\" target=\"_blank\">SynCode</a>: a library for context-free grammar guided generation (JSON, SQL, Python).</li> <li><a href=\"https://github.com/huggingface/text-generation-inference\" rel=\"nofollow\" target=\"_blank\">Text Generation Inference</a>: a production-ready server for LLMs.</li> <li><a href=\"https://github.com/oobabooga/text-generation-webui\" rel=\"nofollow\" target=\"_blank\">Text generation web UI</a>: a Gradio web UI for text generation.</li> <li><a href=\"https://github.com/NVIDIA/logits-processor-zoo\" rel=\"nofollow\" target=\"_blank\">logits-processor-zoo</a>: additional logits processors for controlling text generation.</li></ul> <a class=\"!text-gray-400 !no-underline text-sm flex items-center not-prose mt-4\" href=\"https://github.com/huggingface/transformers/blob/main/docs/source/en/llm_tutorial.md\" target=\"_blank\"><svg aria-hidden=\"true\" class=\"mr-1\" fill=\"currentColor\" focusable=\"false\" height=\"1em\" preserveaspectratio=\"xMidYMid meet\" role=\"img\" viewbox=\"0 0 32 32\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M31,16l-7,7l-1.41-1.41L28.17,16l-5.58-5.59L24,9l7,7z\"></path><path d=\"M1,16l7-7l1.41,1.41L3.83,16l5.58,5.59L8,23l-7-7z\"></path><path d=\"M12.419,25.484L17.639,6.552l1.932,0.518L14.351,26.002z\"></path></svg> <span data-svelte-h=\"svelte-zjs2n5\"><span class=\"underline\">Update</span> on GitHub</span></a> <p></p>\n\n<!-- HTML_TAG_END --></div>\n<div class=\"SVELTE_HYDRATER contents\" data-props=\"{}\" data-target=\"DocHuggingChatInput\"></div>\n<div class=\"SVELTE_HYDRATER contents\" data-props='{\"classNames\":\"mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32\",\"chapterPrev\":{\"title\":\"Adding a new pipeline\",\"id\":\"add_new_pipeline\",\"url\":\"/docs/transformers/add_new_pipeline\"},\"chapterNext\":{\"title\":\"Decoding methods\",\"id\":\"generation_strategies\",\"url\":\"/docs/transformers/generation_strategies\"},\"isCourse\":false,\"isLoggedIn\":false}' data-target=\"DocFooterNav\"><div class=\"mx-auto mt-16 flex max-w-4xl items-center pb-8 font-sans font-medium leading-6 xl:mt-32\"><a class=\"mr-8 flex transform items-center text-gray-600 transition-all hover:-translate-x-px hover:text-gray-900 dark:hover:text-gray-300\" href=\"https://huggingface.co/docs/transformers/add_new_pipeline\" target=\"_blank\"><span class=\"mr-2 translate-y-px\">â</span>Adding a new pipeline</a>\n<a class=\"ml-auto flex transform items-center text-right text-gray-600 transition-all hover:translate-x-px hover:text-gray-900 dark:hover:text-gray-300\" href=\"https://huggingface.co/docs/transformers/generation_strategies\" target=\"_blank\">Decoding methods<span class=\"ml-2 translate-y-px\">â</span></a></div></div></div></div>\n<div class=\"sticky top-0 self-start\"><div class=\"SVELTE_HYDRATER contents\" data-props='{\"chapter\":{\"title\":\"Text generation\",\"isExpanded\":true,\"id\":\"text-generation\",\"url\":\"#text-generation\",\"sections\":[{\"title\":\"Default generate\",\"isExpanded\":true,\"id\":\"default-generate\",\"url\":\"#default-generate\",\"sections\":[]},{\"title\":\"Generation configuration\",\"isExpanded\":true,\"id\":\"generation-configuration\",\"url\":\"#generation-configuration\",\"sections\":[{\"title\":\"Saving\",\"isExpanded\":true,\"id\":\"saving\",\"url\":\"#saving\",\"sections\":[]}]},{\"title\":\"Common Options\",\"isExpanded\":true,\"id\":\"common-options\",\"url\":\"#common-options\",\"sections\":[]},{\"title\":\"Pitfalls\",\"isExpanded\":true,\"id\":\"pitfalls\",\"url\":\"#pitfalls\",\"sections\":[{\"title\":\"Output length\",\"isExpanded\":true,\"id\":\"output-length\",\"url\":\"#output-length\",\"sections\":[]},{\"title\":\"Decoding strategy\",\"isExpanded\":true,\"id\":\"decoding-strategy\",\"url\":\"#decoding-strategy\",\"sections\":[]},{\"title\":\"Padding side\",\"isExpanded\":true,\"id\":\"padding-side\",\"url\":\"#padding-side\",\"sections\":[]},{\"title\":\"Prompt format\",\"isExpanded\":true,\"id\":\"prompt-format\",\"url\":\"#prompt-format\",\"sections\":[]}]},{\"title\":\"Resources\",\"isExpanded\":true,\"id\":\"resources\",\"url\":\"#resources\",\"sections\":[]}]}}' data-target=\"SubSideMenu\">\n</div></div></div>\n<div id=\"doc-footer\"></div></main>",
      "text": "Transformers documentation\nText generation\nTransformers\nð¡ View all docs\nAWS Trainium & Inferentia\nAccelerate\nArgilla\nAutoTrain\nBitsandbytes\nChat UI\nDataset viewer\nDatasets\nDeploying on AWS\nDiffusers\nDistilabel\nEvaluate\nGoogle Cloud\nGoogle TPUs\nGradio\nHub\nHub Python Library\nHuggingface.js\nInference Endpoints (dedicated)\nInference Providers\nKernels\nLeRobot\nLeaderboards\nLighteval\nMicrosoft Azure\nOptimum\nPEFT\nSafetensors\nSentence Transformers\nTRL\nTasks\nText Embeddings Inference\nText Generation Inference\nTokenizers\nTrackio\nTransformers\nTransformers.js\nsmolagents\ntimm\nSearch documentation\nmain\nv5.0.0rc1\nv4.57.3\nv4.56.2\nv4.55.4\nv4.53.3\nv4.52.3\nv4.51.3\nv4.50.0\nv4.49.0\nv4.48.2\nv4.47.1\nv4.46.3\nv4.45.2\nv4.44.2\nv4.43.4\nv4.42.4\nv4.41.2\nv4.40.2\nv4.39.3\nv4.38.2\nv4.37.2\nv4.36.1\nv4.35.2\nv4.34.1\nv4.33.3\nv4.32.1\nv4.31.0\nv4.30.0\nv4.29.1\nv4.28.1\nv4.27.2\nv4.26.1\nv4.25.1\nv4.24.0\nv4.23.1\nv4.22.2\nv4.21.3\nv4.20.1\nv4.19.4\nv4.18.0\nv4.17.0\nv4.16.2\nv4.15.0\nv4.14.1\nv4.13.0\nv4.12.5\nv4.11.3\nv4.10.1\nv4.9.2\nv4.8.2\nv4.7.0\nv4.6.0\nv4.5.1\nv4.4.2\nv4.3.3\nv4.2.2\nv4.1.1\nv4.0.1\nv3.5.1\nv3.4.0\nv3.3.1\nv3.2.0\nv3.1.0\nv3.0.2\nv2.11.0\nv2.10.0\nv2.9.1\nv2.8.0\nv2.7.0\nv2.6.0\nv2.5.1\nv2.4.1\nv2.3.0\nv2.2.2\nv2.1.1\nv2.0.0\nv1.2.0\nv1.1.0\nv1.0.0\ndoc-builder-html\nAR\nDE\nEN\nES\nFR\nHI\nIT\nJA\nKO\nPT\nZH\nJoin the Hugging Face community\nand get access to the augmented documentation experience\nCollaborate on models, datasets and Spaces\nFaster examples with accelerated inference\nSwitch between documentation themes\nSign Up\nto get started\nCopy page\nText generation\nText generation is the most popular application for large language models (LLMs). A LLM is trained to generate the next word (token) given some initial text (prompt) along with its own generated outputs up to a predefined length or when it reaches an end-of-sequence (\nEOS\n) token.\nIn Transformers, the\ngenerate()\nAPI handles text generation, and it is available for all models with generative capabilities. This guide will show you the basics of text generation with\ngenerate()\nand some common pitfalls to avoid.\nFor the following commands, please make sure\ntransformers serve\nis running\n.\nCopied\ntransformers chat Qwen/Qwen2.5-0.5B-Instruct\nDefault generate\nBefore you begin, itâs helpful to install\nbitsandbytes\nto quantize really large models to reduce their memory usage.\nCopied\n!pip install -U transformers bitsandbytes\nBitsandbytes supports multiple backends in addition to CUDA-based GPUs. Refer to the multi-backend installation\nguide\nto learn more.\nLoad a LLM with\nfrom_pretrained()\nand add the following two parameters to reduce the memory requirements.\ndevice_map=\"auto\"\nenables Acceleratesâ\nBig Model Inference\nfeature for automatically initiating the model skeleton and loading and dispatching the model weights across all available devices, starting with the fastest device (GPU).\nquantization_config\nis a configuration object that defines the quantization settings. This examples uses bitsandbytes as the quantization backend (see the\nQuantization\nsection for more available backends) and it loads the model in\n4-bits\n.\nCopied\nfrom\ntransformers\nimport\nAutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nquantization_config = BitsAndBytesConfig(load_in_4bit=\nTrue\n)\nmodel = AutoModelForCausalLM.from_pretrained(\n\"mistralai/Mistral-7B-v0.1\"\n, device_map=\n\"auto\"\n, quantization_config=quantization_config)\nTokenize your input, and set the\npadding_side()\nparameter to\n\"left\"\nbecause a LLM is not trained to continue generation from padding tokens. The tokenizer returns the input ids and attention mask.\nProcess more than one prompt at a time by passing a list of strings to the tokenizer. Batch the inputs to improve throughput at a small cost to latency and memory.\nCopied\ntokenizer = AutoTokenizer.from_pretrained(\n\"mistralai/Mistral-7B-v0.1\"\n, padding_side=\n\"left\"\n)\nmodel_inputs = tokenizer([\n\"A list of colors: red, blue\"\n], return_tensors=\n\"pt\"\n).to(model.device)\nPass the inputs to\ngenerate()\nto generate tokens, and\nbatch_decode()\nthe generated tokens back to text.\nCopied\ngenerated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=\nTrue\n)[\n0\n]\n\"A list of colors: red, blue, green, yellow, orange, purple, pink,\"\nGeneration configuration\nAll generation settings are contained in\nGenerationConfig\n. In the example above, the generation settings are derived from the\ngeneration_config.json\nfile of\nmistralai/Mistral-7B-v0.1\n. A default decoding strategy is used when no configuration is saved with a model.\nInspect the configuration through the\ngeneration_config\nattribute. It only shows values that are different from the default configuration, in this case, the\nbos_token_id\nand\neos_token_id\n.\nCopied\nfrom\ntransformers\nimport\nAutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\n\"mistralai/Mistral-7B-v0.1\"\n, device_map=\n\"auto\"\n)\nmodel.generation_config\nGenerationConfig {\n\"bos_token_id\"\n:\n1\n,\n\"eos_token_id\"\n:\n2\n}\nYou can customize\ngenerate()\nby overriding the parameters and values in\nGenerationConfig\n. See\nthis section below\nfor commonly adjusted parameters.\nCopied\n# enable beam search sampling strategy\nmodel.generate(**inputs, num_beams=\n4\n, do_sample=\nTrue\n)\ngenerate()\ncan also be extended with external libraries or custom code:\nthe\nlogits_processor\nparameter accepts custom\nLogitsProcessor\ninstances for manipulating the next token probability distribution;\nthe\nstopping_criteria\nparameters supports custom\nStoppingCriteria\nto stop text generation;\nother custom generation methods can be loaded through the\ncustom_generate\nflag (\ndocs\n).\nRefer to the\nGeneration strategies\nguide to learn more about search, sampling, and decoding strategies.\nSaving\nCreate an instance of\nGenerationConfig\nand specify the decoding parameters you want.\nCopied\nfrom\ntransformers\nimport\nAutoModelForCausalLM, GenerationConfig\n\nmodel = AutoModelForCausalLM.from_pretrained(\n\"my_account/my_model\"\n)\ngeneration_config = GenerationConfig(\n    max_new_tokens=\n50\n, do_sample=\nTrue\n, top_k=\n50\n, eos_token_id=model.config.eos_token_id\n)\nUse\nsave_pretrained()\nto save a specific generation configuration and set the\npush_to_hub\nparameter to\nTrue\nto upload it to the Hub.\nCopied\ngeneration_config.save_pretrained(\n\"my_account/my_model\"\n, push_to_hub=\nTrue\n)\nLeave the\nconfig_file_name\nparameter empty. This parameter should be used when storing multiple generation configurations in a single directory. It gives you a way to specify which generation configuration to load. You can create different configurations for different generative tasks (creative text generation with sampling, summarization with beam search) for use with a single model.\nCopied\nfrom\ntransformers\nimport\nAutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig\n\ntokenizer = AutoTokenizer.from_pretrained(\n\"google-t5/t5-small\"\n)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\n\"google-t5/t5-small\"\n)\n\ntranslation_generation_config = GenerationConfig(\n    num_beams=\n4\n,\n    early_stopping=\nTrue\n,\n    decoder_start_token_id=\n0\n,\n    eos_token_id=model.config.eos_token_id,\n    pad_token=model.config.pad_token_id,\n)\n\ntranslation_generation_config.save_pretrained(\n\"/tmp\"\n, config_file_name=\n\"translation_generation_config.json\"\n, push_to_hub=\nTrue\n)\n\ngeneration_config = GenerationConfig.from_pretrained(\n\"/tmp\"\n, config_file_name=\n\"translation_generation_config.json\"\n)\ninputs = tokenizer(\n\"translate English to French: Configuration files are easy to use!\"\n, return_tensors=\n\"pt\"\n)\noutputs = model.generate(**inputs, generation_config=generation_config)\nprint\n(tokenizer.batch_decode(outputs, skip_special_tokens=\nTrue\n))\nCommon Options\ngenerate()\nis a powerful tool that can be heavily customized. This can be daunting for a new users. This section contains a list of popular generation options that you can define in most text generation tools in Transformers:\ngenerate()\n,\nGenerationConfig\n,\npipelines\n, the\nchat\nCLI, â¦\nOption name\nType\nSimplified description\nmax_new_tokens\nint\nControls the maximum generation length. Be sure to define it, as it usually defaults to a small value.\ndo_sample\nbool\nDefines whether generation will sample the next token (\nTrue\n), or is greedy instead (\nFalse\n). Most use cases should set this flag to\nTrue\n. Check\nthis guide\nfor more information.\ntemperature\nfloat\nHow unpredictable the next selected token will be. High values (\n>0.8\n) are good for creative tasks, low values (e.g.\n<0.4\n) for tasks that require âthinkingâ. Requires\ndo_sample=True\n.\nnum_beams\nint\nWhen set to\n>1\n, activates the beam search algorithm. Beam search is good on input-grounded tasks. Check\nthis guide\nfor more information.\nrepetition_penalty\nfloat\nSet it to\n>1.0\nif youâre seeing the model repeat itself often. Larger values apply a larger penalty.\neos_token_id\nlist[int]\nThe token(s) that will cause generation to stop. The default value is usually good, but you can specify a different token.\nPitfalls\nThe section below covers some common issues you may encounter during text generation and how to solve them.\nOutput length\ngenerate()\nreturns up to 20 tokens by default unless otherwise specified in a models\nGenerationConfig\n. It is highly recommended to manually set the number of generated tokens with the\nmax_new_tokens\nparameter to control the output length.\nDecoder-only\nmodels returns the initial prompt along with the generated tokens.\nCopied\nmodel_inputs = tokenizer([\n\"A sequence of numbers: 1, 2\"\n], return_tensors=\n\"pt\"\n).to(model.device)\ndefault length\nmax_new_tokens\nCopied\ngenerated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=\nTrue\n)[\n0\n]\n'A sequence of numbers: 1, 2, 3, 4, 5'\nDecoding strategy\nThe default decoding strategy in\ngenerate()\nis\ngreedy search\n, which selects the next most likely token, unless otherwise specified in a models\nGenerationConfig\n. While this decoding strategy works well for input-grounded tasks (transcription, translation), it is not optimal for more creative use cases (story writing, chat applications).\nFor example, enable a\nmultinomial sampling\nstrategy to generate more diverse outputs. Refer to the\nGeneration strategy\nguide for more decoding strategies.\nCopied\nmodel_inputs = tokenizer([\n\"I am a cat.\"\n], return_tensors=\n\"pt\"\n).to(model.device)\ngreedy search\nmultinomial sampling\nCopied\ngenerated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=\nTrue\n)[\n0\n]\nPadding side\nInputs need to be padded if they donât have the same length. But LLMs arenât trained to continue generation from padding tokens, which means the\npadding_side()\nparameter needs to be set to the left of the input.\nright pad\nleft pad\nCopied\nmodel_inputs = tokenizer(\n    [\n\"1, 2, 3\"\n,\n\"A, B, C, D, E\"\n], padding=\nTrue\n, return_tensors=\n\"pt\"\n).to(model.device)\ngenerated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=\nTrue\n)[\n0\n]\n'1, 2, 33333333333'\nPrompt format\nSome models and tasks expect a certain input prompt format, and if the format is incorrect, the model returns a suboptimal output. You can learn more about prompting in the\nprompt engineering\nguide.\nFor example, a chat model expects the input as a\nchat template\n. Your prompt should include a\nrole\nand\ncontent\nto indicate who is participating in the conversation. If you try to pass your prompt as a single string, the model doesnât always return the expected output.\nCopied\nfrom\ntransformers\nimport\nAutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\ntokenizer = AutoTokenizer.from_pretrained(\n\"HuggingFaceH4/zephyr-7b-alpha\"\n)\nmodel = AutoModelForCausalLM.from_pretrained(\n\"HuggingFaceH4/zephyr-7b-alpha\"\n, device_map=\n\"auto\"\n, quantization_config=BitsAndBytesConfig(load_in_4bit=\nTrue\n)\n)\nno format\nchat template\nCopied\nprompt =\n\"\"\"How many cats does it take to change a light bulb? Reply as a pirate.\"\"\"\nmodel_inputs = tokenizer([prompt], return_tensors=\n\"pt\"\n).to(model.device)\ninput_length = model_inputs.input_ids.shape[\n1\n]\ngenerated_ids = model.generate(**model_inputs, max_new_tokens=\n50\n)\nprint\n(tokenizer.batch_decode(generated_ids[:, input_length:], skip_special_tokens=\nTrue\n)[\n0\n])\n\"Aye, matey! 'Tis a simple task for a cat with a keen eye and nimble paws. First, the cat will climb up the ladder, carefully avoiding the rickety rungs. Then, with\"\nResources\nTake a look below for some more specific and specialized text generation libraries.\nOptimum\n: an extension of Transformers focused on optimizing training and inference on specific hardware devices\nOutlines\n: a library for constrained text generation (generate JSON files for example).\nSynCode\n: a library for context-free grammar guided generation (JSON, SQL, Python).\nText Generation Inference\n: a production-ready server for LLMs.\nText generation web UI\n: a Gradio web UI for text generation.\nlogits-processor-zoo\n: additional logits processors for controlling text generation.\nUpdate\non GitHub\nâ\nAdding a new pipeline\nDecoding methods\nâ",
      "code_blocks": [
        {
          "lang": "",
          "code": "transformers chat Qwen/Qwen2.5-0.5B-Instruct"
        },
        {
          "lang": "",
          "code": "!pip install -U transformers bitsandbytes"
        },
        {
          "lang": "",
          "code": "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\nquantization_config = BitsAndBytesConfig(load_in_4bit=True)\nmodel = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", device_map=\"auto\", quantization_config=quantization_config)"
        },
        {
          "lang": "",
          "code": "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", padding_side=\"left\")\nmodel_inputs = tokenizer([\"A list of colors: red, blue\"], return_tensors=\"pt\").to(model.device)"
        },
        {
          "lang": "",
          "code": "generated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n\"A list of colors: red, blue, green, yellow, orange, purple, pink,\""
        },
        {
          "lang": "",
          "code": "from transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", device_map=\"auto\")\nmodel.generation_config\nGenerationConfig {\n  \"bos_token_id\": 1,\n  \"eos_token_id\": 2\n}"
        },
        {
          "lang": "",
          "code": "# enable beam search sampling strategy\nmodel.generate(**inputs, num_beams=4, do_sample=True)"
        },
        {
          "lang": "",
          "code": "from transformers import AutoModelForCausalLM, GenerationConfig\n\nmodel = AutoModelForCausalLM.from_pretrained(\"my_account/my_model\")\ngeneration_config = GenerationConfig(\n    max_new_tokens=50, do_sample=True, top_k=50, eos_token_id=model.config.eos_token_id\n)"
        },
        {
          "lang": "",
          "code": "generation_config.save_pretrained(\"my_account/my_model\", push_to_hub=True)"
        },
        {
          "lang": "",
          "code": "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, GenerationConfig\n\ntokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"google-t5/t5-small\")\n\ntranslation_generation_config = GenerationConfig(\n    num_beams=4,\n    early_stopping=True,\n    decoder_start_token_id=0,\n    eos_token_id=model.config.eos_token_id,\n    pad_token=model.config.pad_token_id,\n)\n\ntranslation_generation_config.save_pretrained(\"/tmp\", config_file_name=\"translation_generation_config.json\", push_to_hub=True)\n\ngeneration_config = GenerationConfig.from_pretrained(\"/tmp\", config_file_name=\"translation_generation_config.json\")\ninputs = tokenizer(\"translate English to French: Configuration files are easy to use!\", return_tensors=\"pt\")\noutputs = model.generate(**inputs, generation_config=generation_config)\nprint(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
        },
        {
          "lang": "",
          "code": "model_inputs = tokenizer([\"A sequence of numbers: 1, 2\"], return_tensors=\"pt\").to(model.device)"
        },
        {
          "lang": "",
          "code": "generated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n'A sequence of numbers: 1, 2, 3, 4, 5'"
        },
        {
          "lang": "",
          "code": "model_inputs = tokenizer([\"I am a cat.\"], return_tensors=\"pt\").to(model.device)"
        },
        {
          "lang": "",
          "code": "generated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
        },
        {
          "lang": "",
          "code": "model_inputs = tokenizer(\n    [\"1, 2, 3\", \"A, B, C, D, E\"], padding=True, return_tensors=\"pt\"\n).to(model.device)\ngenerated_ids = model.generate(**model_inputs)\ntokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n'1, 2, 33333333333'"
        },
        {
          "lang": "",
          "code": "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\ntokenizer = AutoTokenizer.from_pretrained(\"HuggingFaceH4/zephyr-7b-alpha\")\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"HuggingFaceH4/zephyr-7b-alpha\", device_map=\"auto\", quantization_config=BitsAndBytesConfig(load_in_4bit=True)\n)"
        },
        {
          "lang": "",
          "code": "prompt = \"\"\"How many cats does it take to change a light bulb? Reply as a pirate.\"\"\"\nmodel_inputs = tokenizer([prompt], return_tensors=\"pt\").to(model.device)\ninput_length = model_inputs.input_ids.shape[1]\ngenerated_ids = model.generate(**model_inputs, max_new_tokens=50)\nprint(tokenizer.batch_decode(generated_ids[:, input_length:], skip_special_tokens=True)[0])\n\"Aye, matey! 'Tis a simple task for a cat with a keen eye and nimble paws. First, the cat will climb up the ladder, carefully avoiding the rickety rungs. Then, with\""
        }
      ],
      "headings": [
        {
          "level": 1,
          "text": "Transformers"
        },
        {
          "level": 1,
          "text": "Text generation"
        },
        {
          "level": 2,
          "text": "Default generate"
        },
        {
          "level": 2,
          "text": "Generation configuration"
        },
        {
          "level": 3,
          "text": "Saving"
        },
        {
          "level": 2,
          "text": "Common Options"
        },
        {
          "level": 2,
          "text": "Pitfalls"
        },
        {
          "level": 3,
          "text": "Output length"
        },
        {
          "level": 3,
          "text": "Decoding strategy"
        },
        {
          "level": 3,
          "text": "Padding side"
        },
        {
          "level": 3,
          "text": "Prompt format"
        },
        {
          "level": 2,
          "text": "Resources"
        }
      ]
    }
  ]
}